{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Handling missing data\n",
    "\n",
    "> Missing values, including absent datapoints due to up-sampling, were imputed by last observation carried forward (LOCF). Population medians in the datasets were used for missing values occurring before the first actual measurement.\n",
    "\n",
    "This should be done before normalisation (but after dummy encoding)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "verbose = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_path = '/Users/jk1/stroke_datasets/stroke_unit_dataset/per_value/Extraction_20220815'\n",
    "admission_data_path = '/Users/jk1/OneDrive - unige.ch/stroke_research/geneva_stroke_unit_dataset/data/stroke_registry/post_hoc_modified/stroke_registry_post_hoc_modified.xlsx'\n",
    "patient_selection_path = '/Users/jk1/temp/opsum_extraction_output/high_frequency_data_patient_selection_with_details.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from preprocessing.variable_assembly.variable_database_assembly import assemble_variable_database\n",
    "\n",
    "feature_df = assemble_variable_database(data_path, admission_data_path, patient_selection_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from preprocessing.variable_assembly.relative_timestamps import transform_to_relative_timestamps\n",
    "from preprocessing.encoding_categorical_variables.encode_categorical_variables import encode_categorical_variables\n",
    "\n",
    "restricted_feature_df = transform_to_relative_timestamps(feature_df, drop_old_columns=False, restrict_to_time_range=True)\n",
    "cat_encoded_restricted_feature_df = encode_categorical_variables(restricted_feature_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from preprocessing.resample_to_time_bins.resample_to_hourly_features import resample_to_hourly_features\n",
    "\n",
    "resampled_df = resample_to_hourly_features(cat_encoded_restricted_feature_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "resampled_df.head(500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for label in resampled_df.sample_label.unique():\n",
    "   print(f\"'{label}',\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "categorical_vars = [\n",
    "    'sex_male',\n",
    "'referral_in-hospital_event',\n",
    "'referral_other_hospital',\n",
    "'referral_self_referral_or_gp',\n",
    "'prestroke_disability_(rankin)_1.0',\n",
    "'prestroke_disability_(rankin)_2.0',\n",
    "'prestroke_disability_(rankin)_3.0',\n",
    "'prestroke_disability_(rankin)_4.0',\n",
    "'prestroke_disability_(rankin)_5.0',\n",
    "'antihypert._drugs_pre-stroke_yes',\n",
    "'lipid_lowering_drugs_pre-stroke_yes',\n",
    "'antiplatelet_drugs_yes',\n",
    "'anticoagulants_yes',\n",
    "'medhist_hypertension_yes',\n",
    "'medhist_diabetes_yes',\n",
    "'medhist_hyperlipidemia_yes',\n",
    "'medhist_smoking_yes',\n",
    "'medhist_atrial_fibr._yes',\n",
    "'medhist_chd_yes',\n",
    "'medhist_pad_yes',\n",
    "'medhist_cerebrovascular_event_true',\n",
    "'categorical_onset_to_admission_time_541-1440min',\n",
    "'categorical_onset_to_admission_time_<270min',\n",
    "'categorical_onset_to_admission_time_>1440min',\n",
    "'categorical_onset_to_admission_time_intra_hospital',\n",
    "'categorical_onset_to_admission_time_onset_unknown',\n",
    "'wake_up_stroke_true',\n",
    "'categorical_ivt_91-270min',\n",
    "'categorical_ivt_<90min',\n",
    "'categorical_ivt_>540min',\n",
    "'categorical_ivt_no_ivt',\n",
    "'categorical_iat_<270min',\n",
    "'categorical_iat_>540min',\n",
    "'categorical_iat_no_iat',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for label in resampled_df.sample_label.unique():\n",
    "   if label not in categorical_vars:\n",
    "        print(f\"'{label}',\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## First hour missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "len(resampled_df.case_admission_id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# count number of values per sample_label in the first hour\n",
    "resampled_df[resampled_df.relative_sample_date_hourly_cat == 0].groupby('sample_label').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Continuous vars\n",
    "# first hour population means for sample_labels not in categorical_vars\n",
    "resampled_df[(resampled_df.relative_sample_date_hourly_cat == 0) & (~resampled_df.sample_label.isin(categorical_vars))].groupby('sample_label').value.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "resampled_df[(resampled_df.relative_sample_date_hourly_cat == 0) & (~resampled_df.sample_label.isin(categorical_vars))].groupby('sample_label').value.median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Median seems to be a better imputation method than mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# categorical vars\n",
    "# first hour population mode for sample_labels in categorical_vars\n",
    "resampled_df[(resampled_df.relative_sample_date_hourly_cat == 0) & (resampled_df.sample_label.isin(categorical_vars))].groupby('sample_label').value.apply(lambda x: x.mode()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Imputing missing values after categorical encoding seems to be ok, as mutual exclusivity is not violated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "imputed_missing_df = resampled_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# find case_admission_id with no sample_label == FiO2\n",
    "n_subj_noFIO2 = len(set(imputed_missing_df.case_admission_id.unique()).difference(set(imputed_missing_df[(imputed_missing_df.sample_label == 'FIO2') & (imputed_missing_df.relative_sample_date_hourly_cat == 0)].case_admission_id.unique())))\n",
    "print(f'{n_subj_noFIO2} subjects with no FiO2 in first hour. Value will be replaced with 21%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Handle first missing values (timebin 0)\n",
    "# -> fill with population median/mode\n",
    "if verbose:\n",
    "    print('Fill fist missing values via population mean/median.')\n",
    "for sample_label in tqdm(imputed_missing_df.sample_label.unique()):\n",
    "    # find case_admission_ids with no value for sample_label in first timebin\n",
    "    patients_with_no_sample_label_tp0 = set(imputed_missing_df.case_admission_id.unique()).difference(set(\n",
    "        imputed_missing_df[(imputed_missing_df.sample_label == sample_label) & (\n",
    "                    imputed_missing_df.relative_sample_date_hourly_cat == 0)].case_admission_id.unique()))\n",
    "\n",
    "    if sample_label == 'FIO2':\n",
    "        # for FIO2, impute with 21.0%\n",
    "        imputed_tp0_value = 21.0\n",
    "    elif sample_label in categorical_vars:\n",
    "        # for categorical vars, impute with mode\n",
    "        imputed_tp0_value = imputed_missing_df[(imputed_missing_df.sample_label == sample_label) & (\n",
    "                    imputed_missing_df.relative_sample_date_hourly_cat == 0)].value.mode()[0]\n",
    "    else:\n",
    "        # for numerical vars, impute with median\n",
    "        imputed_tp0_value = imputed_missing_df[(imputed_missing_df.sample_label == sample_label) & (\n",
    "                    imputed_missing_df.relative_sample_date_hourly_cat == 0)].value.median()\n",
    "    if verbose:\n",
    "        print(\n",
    "            f'{len(patients_with_no_sample_label_tp0)} patients with no {sample_label} in first timebin for which {imputed_tp0_value} was imputed')\n",
    "\n",
    "    sample_label_original_source = \\\n",
    "        imputed_missing_df[imputed_missing_df.sample_label == sample_label].source.mode(dropna=True)[0]\n",
    "\n",
    "    imputed_sample_label = pd.DataFrame({'case_admission_id': list(patients_with_no_sample_label_tp0),\n",
    "                                         'sample_label': sample_label,\n",
    "                                         'relative_sample_date_hourly_cat': 0,\n",
    "                                         'source': f'{sample_label_original_source}_pop_imputed',\n",
    "                                         'value': imputed_tp0_value})\n",
    "\n",
    "    # impute missing values for sample_label in first timebin\n",
    "    imputed_missing_df = imputed_missing_df.append(imputed_sample_label, ignore_index=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Following Missing timebins\n",
    "\n",
    "> Fill missing timebin values by last observation carried forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "locf_imputed_missing_df = imputed_missing_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "temp = locf_imputed_missing_df[(locf_imputed_missing_df.case_admission_id == '571703_7379') & (locf_imputed_missing_df.sample_label == 'FIO2')]\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "temp[(temp.case_admission_id == '571703_7379') & (temp.sample_label == 'FIO2')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "temp.set_index('relative_sample_date_hourly_cat').reindex(range(0,70)).fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "temp = locf_imputed_missing_df[(locf_imputed_missing_df.case_admission_id.isin(['571703_7379', '100023_4784']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# following missing values (timebin > 0)\n",
    "# -> Fill missing timebin values by last observation carried forward\n",
    "if verbose:\n",
    "    print('Fill missing values via LOCF.')\n",
    "\n",
    "locf_imputed_missing_df = temp.groupby(['case_admission_id', 'sample_label']).apply(\n",
    "    lambda x: x.set_index('relative_sample_date_hourly_cat').reindex(range(0, 72)))\n",
    "locf_imputed_missing_df.value = locf_imputed_missing_df.value.fillna(method='ffill')\n",
    "locf_imputed_missing_df.sample_label = locf_imputed_missing_df.sample_label.fillna(method='ffill')\n",
    "locf_imputed_missing_df.case_admission_id = locf_imputed_missing_df.case_admission_id.fillna(method='ffill')\n",
    "\n",
    "locf_imputed_missing_df['source_imputation'] = locf_imputed_missing_df.source.apply(lambda x: '' if type(x) == str else np.nan)\n",
    "locf_imputed_missing_df.source_imputation = locf_imputed_missing_df.source_imputation.fillna('_locf_imputed')\n",
    "locf_imputed_missing_df.source = locf_imputed_missing_df.source.fillna(method='ffill')\n",
    "locf_imputed_missing_df.source += locf_imputed_missing_df.source_imputation\n",
    "locf_imputed_missing_df.drop(columns=['source_imputation'], inplace=True)\n",
    "\n",
    "# reset relative_sample_date_hourly_cat as column\n",
    "locf_imputed_missing_df.reset_index(level=2, inplace=True)\n",
    "# drop groupby index\n",
    "locf_imputed_missing_df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "locf_imputed_missing_df.source.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "locf_imputed_missing_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Testing final function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "log_dir = '/Users/jk1/temp/opsum_prepro_output/temp_output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from preprocessing.handling_missing_values.impute_missing_values import impute_missing_values\n",
    "\n",
    "imputed_resampled_df = impute_missing_values(resampled_df, log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "temp = imputed_resampled_df.head(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def assert_selected_variables_presence(df: pd.DataFrame, variable_selection_path: str):\n",
    "    \"\"\"\n",
    "    Asserts that all variables from the variable selection file are present in the dataframe.\n",
    "    :param df: the dataframe to be checked\n",
    "    :param variable_selection_path: the path to the variable selection file\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    selected_variables = pd.read_excel(variable_selection_path)['included']\n",
    "    missing_variables = []\n",
    "    for variable in selected_variables:\n",
    "        if (len([s for s in df.sample_label.unique() if variable in s]) == 0)\\\n",
    "                & (len([s for s in df.sample_label.unique() if variable.lower().replace(' ', '_') in s]) == 0):\n",
    "            missing_variables.append(variable)\n",
    "\n",
    "    # missing_variables = set(selected_variables).difference(set(df.sample_label.unique()))\n",
    "    if len(missing_variables) > 0:\n",
    "        raise ValueError(f'The following variables are missing from the dataframe: {missing_variables}')\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "desired_time_range = 72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# from preprocessing.variable_assembly.variable_selection import assert_selected_variables_presence\n",
    "\n",
    "all_variables_present = []\n",
    "\n",
    "selected_variables_path = '/Users/jk1/stroke_research/OPSUM/preprocessing/variable_assembly/selected_variables.xlsx'\n",
    "# selected_variables_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'variable_assembly/selected_variables.xlsx')\n",
    "\n",
    "for cid in tqdm(imputed_resampled_df.case_admission_id.unique()):\n",
    "    temp_cid_df = imputed_resampled_df[(imputed_resampled_df.case_admission_id == cid)]\n",
    "    for time_bin in range(desired_time_range):\n",
    "        all_variables_present.append(assert_selected_variables_presence(temp_cid_df[temp_cid_df.relative_sample_date_hourly_cat == time_bin], selected_variables_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "all(all_variables_present)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "temp_cid_df[temp_cid_df.relative_sample_date_hourly_cat == time_bin]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "assert_selected_variables_presence(temp.groupby(['case_admission_id', 'relative_sample_date_hourly_cat']), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

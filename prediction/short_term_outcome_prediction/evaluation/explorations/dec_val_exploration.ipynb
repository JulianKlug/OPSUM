{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T09:21:02.834668Z",
     "start_time": "2025-04-03T09:21:02.828658Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import torch as ch\n",
    "import numpy as np\n",
    "from numba.np.arrayobj import np_concatenate\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import matthews_corrcoef, average_precision_score, roc_auc_score, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pytorch_lightning as pl\n",
    "from prediction.outcome_prediction.Transformer.utils.utils import DictLogger\n",
    "from prediction.outcome_prediction.Transformer.architecture import OPSUMTransformer, OPSUM_encoder_decoder\n",
    "from prediction.outcome_prediction.Transformer.lightning_wrapper import LitEncoderRegressionModel, \\\n",
    "    LitEncoderDecoderModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c81a8b014c760ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T09:13:49.933397Z",
     "start_time": "2025-04-03T09:13:49.924641Z"
    }
   },
   "outputs": [],
   "source": [
    "# data_path = '/Users/jk1/temp/opsum_end/preprocessing/gsu_Extraction_20220815_prepro_08062024_083500/early_neurological_deterioration_train_data_splits/train_data_splits_early_neurological_deterioration_ts0.8_rs42_ns5.pth'\n",
    "data_path = '/Users/jk1/Downloads/train_data_splits_early_neurological_deterioration_ts0.8_rs42_ns5.pth'\n",
    "model_path = '/Users/jk1/Downloads/checkpoints_short_opsum_transformer_20240822_051920_cv_1/short_opsum_dec_transformer_epoch=02_val_cos_sim=0.9611.ckpt'\n",
    "model_hyperparams_path = '/Users/jk1/Downloads/checkpoints_short_opsum_transformer_20240822_051920_cv_1/best_enc_dec_df.csv'\n",
    "normalisation_data_path = '/Users/jk1/temp/opsum_end/preprocessing/gsu_Extraction_20220815_prepro_08062024_083500/logs_08062024_083500/normalisation_parameters.csv'\n",
    "outcome_data_path = '/Users/jk1/temp/opsum_end/preprocessing/gsu_Extraction_20220815_prepro_08062024_083500/preprocessed_outcomes_short_term_08062024_083500.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed7fa90a243620c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T10:15:07.404481Z",
     "start_time": "2025-04-03T10:15:07.401610Z"
    }
   },
   "outputs": [],
   "source": [
    "use_gpu = False\n",
    "n_time_steps = 72\n",
    "eval_n_time_steps_before_event = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59a9213c94407b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T09:13:51.487494Z",
     "start_time": "2025-04-03T09:13:51.463477Z"
    }
   },
   "outputs": [],
   "source": [
    "model_config = pd.read_csv(model_hyperparams_path)\n",
    "model_config = model_config.to_dict(orient='records')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf30c2e73690e1e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T09:18:16.597526Z",
     "start_time": "2025-04-03T09:18:16.592729Z"
    }
   },
   "outputs": [],
   "source": [
    "model_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f1fcec27391646",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T09:14:32.980735Z",
     "start_time": "2025-04-03T09:14:32.132032Z"
    }
   },
   "outputs": [],
   "source": [
    "splits = ch.load(os.path.join(data_path))\n",
    "full_X_train, full_X_val, y_train, y_val = splits[model_config['best_cv_fold']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e6f490",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalisation_parameters_df = pd.read_csv(normalisation_data_path)\n",
    "outcome_df = pd.read_csv(outcome_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7977abd59a7563",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T10:07:41.910682Z",
     "start_time": "2025-04-03T10:07:41.905603Z"
    }
   },
   "outputs": [],
   "source": [
    "full_X_train[0, 0, :, -2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2836b3b4ba29bf13",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T10:09:42.988896Z",
     "start_time": "2025-04-03T10:09:42.983752Z"
    }
   },
   "outputs": [],
   "source": [
    "# find index of max_NIHSS\n",
    "max_NIHSS_idx = np.where(full_X_train[0, 0, :, -2] == 'max_NIHSS')[0][0]\n",
    "# find index of min_NIHSS\n",
    "min_NIHSS_idx = np.where(full_X_train[0, 0, :, -2] == 'min_NIHSS')[0][0]\n",
    "\n",
    "# find heart_rate\n",
    "heart_rate_idx = np.where(full_X_train[0, 0, :, -2] == 'max_heart_rate')[0][0]\n",
    "# find systolic_blood_pressure\n",
    "systolic_blood_pressure_idx = np.where(full_X_train[0, 0, :, -2] == 'median_systolic_blood_pressure')[0][0]\n",
    "\n",
    "max_NIHSS_idx, min_NIHSS_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41c0fbf3c361933",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T09:15:34.145363Z",
     "start_time": "2025-04-03T09:15:34.132122Z"
    }
   },
   "outputs": [],
   "source": [
    "# prepare input data\n",
    "X_train = full_X_train[:, :, :, -1].astype('float32')\n",
    "X_val = full_X_val[:, :, :, -1].astype('float32')\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train.reshape(-1, X_train.shape[-1])).reshape(X_train.shape)\n",
    "X_val = scaler.transform(X_val.reshape(-1, X_train.shape[-1])).reshape(X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f527d45fa67df0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T09:21:27.752518Z",
     "start_time": "2025-04-03T09:21:10.361349Z"
    }
   },
   "outputs": [],
   "source": [
    "accelerator = 'gpu' if use_gpu else 'cpu'\n",
    "\n",
    "ff_factor = 2\n",
    "ff_dim = ff_factor * model_config['model_dim']\n",
    "pos_encode_factor = 1\n",
    "\n",
    "input_dim = X_val.shape[-1]\n",
    "\n",
    "logger = DictLogger(0)\n",
    "trainer = pl.Trainer(accelerator=accelerator, devices=1, max_epochs=1000,\n",
    "                     gradient_clip_val=model_config['grad_clip_value'], logger=logger)\n",
    "\n",
    "model_architecture = OPSUM_encoder_decoder(\n",
    "            input_dim=input_dim,\n",
    "            num_layers=int(model_config['num_layers']),\n",
    "            num_decoder_layers=int(model_config['num_decoder_layers']),\n",
    "            model_dim=int(model_config['model_dim']),\n",
    "            dropout=int(model_config['dropout']),\n",
    "            ff_dim=int(ff_dim),\n",
    "            num_heads=int(model_config['num_head']),\n",
    "            pos_encode_factor=pos_encode_factor,\n",
    "            n_tokens=1,\n",
    "            max_dim=5000,\n",
    "            layer_norm_eps=1e-05)\n",
    "\n",
    "trained_model = LitEncoderDecoderModel.load_from_checkpoint(checkpoint_path=model_path, model=model_architecture,\n",
    "                                              lr=model_config['lr'],\n",
    "                                              wd=model_config['weight_decay'],\n",
    "                                              train_noise=model_config['train_noise'],\n",
    "                                              loss_function='mse',\n",
    "                                            lr_warmup_steps=model_config['n_lr_warm_up_steps'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e25aef7bedf13d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T13:15:56.938102Z",
     "start_time": "2025-04-03T13:15:56.933537Z"
    }
   },
   "outputs": [],
   "source": [
    "ts = 20\n",
    "modified_time_steps = ts+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc41a31943b571a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T13:15:57.882623Z",
     "start_time": "2025-04-03T13:15:57.559740Z"
    }
   },
   "outputs": [],
   "source": [
    "# X_val_with_first_n_ts = X_val[:, 0:modified_time_steps, :]\n",
    "# y_placeholder = ch.zeros((X_val_with_first_n_ts.shape[0], 1))\n",
    "# if use_gpu:\n",
    "#     val_dataset = TensorDataset(ch.from_numpy(X_val_with_first_n_ts).cuda(), y_placeholder.cuda())\n",
    "# else:\n",
    "#     val_dataset = TensorDataset(ch.from_numpy(X_val_with_first_n_ts), y_placeholder)\n",
    "\n",
    "# val_loader = DataLoader(val_dataset, batch_size=1024)\n",
    "# if ts == 0:\n",
    "#     y_pred = np.array(trainer.predict(trained_model, val_loader)[0])\n",
    "# else:\n",
    "#     y_pred = np.array(trainer.predict(trained_model, val_loader)[0][:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45fb6bda7d9bfd3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T13:17:25.744135Z",
     "start_time": "2025-04-03T13:17:25.712862Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict_n_next_steps(input_data, n_steps, model, trainer):\n",
    "    \"\"\"\n",
    "    Predict the next n_steps using the model and trainer.\n",
    "    :param input_data: The input data to predict on.\n",
    "    :param n_steps: The number of steps to predict.\n",
    "    :param model: The model to use for prediction.\n",
    "    :param trainer: The trainer to use for prediction.\n",
    "    :return: The predictions for the next n_steps.\n",
    "    \"\"\"\n",
    "\n",
    "    predictions = []\n",
    "    for i in tqdm(range(n_steps)):\n",
    "        # first predictions only relies on past date\n",
    "        if i == 0:\n",
    "            input_np = input_data\n",
    "        else:\n",
    "            # append last prediction to input\n",
    "            input_np = np.concatenate([input_np, np.expand_dims(predictions[-1], axis=1)], axis=1)\n",
    "\n",
    "        if use_gpu:\n",
    "            input_dataset = TensorDataset(ch.from_numpy(input_np).cuda(), y_placeholder.cuda())\n",
    "        else:\n",
    "            input_dataset = TensorDataset(ch.from_numpy(input_np), y_placeholder)\n",
    "\n",
    "        input_loader = DataLoader(input_dataset, batch_size=1024)\n",
    "\n",
    "\n",
    "        y_pred = np.array(trainer.predict(model, input_loader)[0][:, -1])\n",
    "\n",
    "        # append prediction to list\n",
    "        predictions.append(y_pred)\n",
    "\n",
    "    predictions_np = np.concatenate([np.expand_dims(predictions[i], axis=1) for i in range(len(predictions))], axis=1)\n",
    "    return predictions_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f108c1bb3db8f801",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T13:17:37.588676Z",
     "start_time": "2025-04-03T13:17:26.507621Z"
    }
   },
   "outputs": [],
   "source": [
    "# predict recursively for eval_n_time_steps_before_event time steps\n",
    "X_val_with_first_n_ts = X_val[:, 0:modified_time_steps, :]\n",
    "y_placeholder = ch.zeros((X_val_with_first_n_ts.shape[0], 1))\n",
    "\n",
    "predictions_np = predict_n_next_steps(X_val_with_first_n_ts, eval_n_time_steps_before_event, trained_model, trainer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d8663019a2cbfb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T13:17:47.200847Z",
     "start_time": "2025-04-03T13:17:47.195430Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10721ac79cec7e78",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T13:17:48.132396Z",
     "start_time": "2025-04-03T13:17:48.127803Z"
    }
   },
   "outputs": [],
   "source": [
    "var_idx = max_NIHSS_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2acc57d2d758770",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-03T13:17:50.261759Z",
     "start_time": "2025-04-03T13:17:48.786791Z"
    }
   },
   "outputs": [],
   "source": [
    "# for every subject, plot the actual values of the variable over time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "for i in range(X_val.shape[0]):\n",
    "# for i in range(5):\n",
    "\n",
    "    plt.plot(X_val[i, :, var_idx])\n",
    "    # predictions start at time step modified_time_steps\n",
    "    plt.plot(np.arange(modified_time_steps, modified_time_steps + eval_n_time_steps_before_event),\n",
    "             predictions_np[i, :, var_idx], 'ro-')\n",
    "    plt.title(f'Subject {i}, Variable {var_idx}')\n",
    "\n",
    "    plt.xlabel('Time step')\n",
    "    plt.ylabel('Value')\n",
    "    plt.ylim(-2.5, 2.5)\n",
    "\n",
    "    # add a light grey vertical arrow pointing at at modified_time_steps\n",
    "    plt.axvline(x=modified_time_steps, color='lightgrey', linestyle='--')\n",
    "\n",
    "    plt.legend(['Actual', 'Predicted'])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b791aad",
   "metadata": {},
   "source": [
    "get delta NIHSS from current timestep to last predicted timestep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fbdbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_normalisation(data, variable_name, normalisation_parameters_df):\n",
    "    \"\"\"\n",
    "    Reverse normalisation of the data.\n",
    "    :param data: The data to reverse normalise.\n",
    "    :param variable_name: The name of the variable to reverse normalise.\n",
    "    :return: The reverse normalised data.\n",
    "    \"\"\"\n",
    "    # Get the original mean and std from the normalisation parameters\n",
    "    # Reverse normalisation\n",
    "    std = normalisation_parameters_df[normalisation_parameters_df.variable == variable_name].original_std.iloc[0]\n",
    "    mean = normalisation_parameters_df[normalisation_parameters_df.variable == variable_name].original_mean.iloc[0]\n",
    "    data = (data * std) + mean\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39b8a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_min_NIHSS_up_to_current_timestep = np.min(full_X_val[:, 0:ts+1, min_NIHSS_idx, -1], axis=1)\n",
    "reverse_scaled_predictions = scaler.inverse_transform(predictions_np.reshape(-1, X_train.shape[-1])).reshape(predictions_np.shape)\n",
    "norm_max_NIHSS_at_last_prediction_timestep = reverse_scaled_predictions[:, -1, max_NIHSS_idx]\n",
    "norm_delta_NIHSS_at_last_predicted_ts = norm_max_NIHSS_at_last_prediction_timestep - norm_min_NIHSS_up_to_current_timestep\n",
    "\n",
    "max_NIHSS_at_last_prediction_timestep = reverse_normalisation(norm_max_NIHSS_at_last_prediction_timestep, 'max_NIHSS', normalisation_parameters_df)\n",
    "min_NIHSS_up_to_current_timestep = reverse_normalisation(norm_min_NIHSS_up_to_current_timestep, 'min_NIHSS', normalisation_parameters_df)\n",
    "delta_NIHSS_at_last_predicted_ts = max_NIHSS_at_last_prediction_timestep - min_NIHSS_up_to_current_timestep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfda5ed",
   "metadata": {},
   "source": [
    "compute metrics at a single timestep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28b5d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_patient_cids = full_X_val[:, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64500723",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluated_ts = ts + eval_n_time_steps_before_event\n",
    "\n",
    "outcome_at_evaluated_ts_df = outcome_df[outcome_df['relative_sample_date_hourly_cat'] == evaluated_ts]\n",
    "# outcome_at_evaluated_ts_df = outcome_df[(outcome_df['relative_sample_date_hourly_cat'] > ts) & (outcome_df['relative_sample_date_hourly_cat'] <= evaluated_ts)]\n",
    "# gt at ts is 0/1 if the patient is in the outcome group at the evaluated time step\n",
    "y_true_at_evaluated_ts = np.isin(val_patient_cids, outcome_at_evaluated_ts_df['case_admission_id'].values).astype(np.int32)\n",
    "\n",
    "y_pred = norm_delta_NIHSS_at_last_predicted_ts\n",
    "y_pred_binary = delta_NIHSS_at_last_predicted_ts >= 4\n",
    "\n",
    "# if len(np.unique(y_true)) == 1:\n",
    "#     roc_scores.append(np.nan)\n",
    "#     auprc_scores.append(np.nan)\n",
    "#     mcc_scores.append(np.nan)\n",
    "# else:\n",
    "#     roc_scores.append(roc_auc_score(y_true, y_pred))\n",
    "#     auprc_scores.append(average_precision_score(y_true, y_pred))\n",
    "#     mcc_scores.append(matthews_corrcoef(y_true, y_pred_binary))\n",
    "print(f'ROC AUC: {roc_auc_score(y_true_at_evaluated_ts, y_pred):.4f}')\n",
    "print(f'AUPRC: {average_precision_score(y_true_at_evaluated_ts, y_pred):.4f}')\n",
    "print(f'MCC: {matthews_corrcoef(y_true_at_evaluated_ts, y_pred_binary):.4f}')\n",
    "print(f'Accuracy: {accuracy_score(y_true_at_evaluated_ts, y_pred_binary):.4f}')\n",
    "\n",
    "# number FP / number TP / number TN / number FN\n",
    "from sklearn.metrics import confusion_matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_true_at_evaluated_ts, y_pred_binary).ravel()\n",
    "print(f'FP: {fp}, TP: {tp}, TN: {tn}, FN: {fn}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4afe210",
   "metadata": {},
   "source": [
    "loop through all timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800eb3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute predictions\n",
    "pred_over_ts = []\n",
    "# for ts in tqdm(range(n_time_steps)):\n",
    "for ts in tqdm(range(10)):\n",
    "    modified_time_steps = ts+1\n",
    "    # predict recursively for eval_n_time_steps_before_event time steps\n",
    "    X_val_with_first_n_ts = X_val[:, 0:modified_time_steps, :]\n",
    "    y_placeholder = ch.zeros((X_val_with_first_n_ts.shape[0], 1))\n",
    "\n",
    "    predictions_np = predict_n_next_steps(X_val_with_first_n_ts, eval_n_time_steps_before_event, trained_model, trainer)\n",
    "    pred_over_ts.append(predictions_np)\n",
    "\n",
    "pred_over_ts_np = np.squeeze(pred_over_ts)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cee6f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_X_val.shape, X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca84e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_scores = []\n",
    "auprc_scores = []\n",
    "mcc_scores = []\n",
    "accuracy_scores = []\n",
    "# count number of positive samples for each time step\n",
    "n_pos_samples = []\n",
    "timesteps = []\n",
    "\n",
    "overall_prediction_df = pd.DataFrame(columns=['timestep', 'prediction', 'true_label'])\n",
    "\n",
    "# for ts in range(n_time_steps):\n",
    "for ts in range(10):\n",
    "    evaluated_ts = ts + eval_n_time_steps_before_event\n",
    "\n",
    "    # GT at evaluated time step\n",
    "    outcome_at_evaluated_ts_df = outcome_df[outcome_df['relative_sample_date_hourly_cat'] == evaluated_ts]\n",
    "    # gt at ts is 0/1 if the patient is in the outcome group at the evaluated time step\n",
    "    y_true_at_evaluated_ts = np.isin(val_patient_cids, outcome_at_evaluated_ts_df['case_admission_id'].values).astype(np.int32)\n",
    "\n",
    "    # prediction at evaluated time step\n",
    "    predictions_at_ts_np = pred_over_ts_np[ts]\n",
    "\n",
    "    # prediction at evaluated time step\n",
    "    # norm_min_NIHSS_up_to_current_timestep = np.min(X_val[:, 0:ts+1, min_NIHSS_idx], axis=1)\n",
    "    # norm_max_NIHSS_at_last_prediction_timestep = pred_over_ts_np[ts, :, -1, max_NIHSS_idx]\n",
    "    norm_min_NIHSS_up_to_current_timestep = np.min(full_X_val[:, 0:ts+1, min_NIHSS_idx, -1], axis=1)\n",
    "    reverse_scaled_predictions = scaler.inverse_transform(predictions_at_ts_np.reshape(-1, X_train.shape[-1])).reshape(predictions_at_ts_np.shape)\n",
    "    norm_max_NIHSS_at_last_prediction_timestep = reverse_scaled_predictions[:, -1, max_NIHSS_idx]\n",
    "    norm_delta_NIHSS_at_last_predicted_ts = norm_max_NIHSS_at_last_prediction_timestep - norm_min_NIHSS_up_to_current_timestep\n",
    "\n",
    "    max_NIHSS_at_last_prediction_timestep = reverse_normalisation(norm_max_NIHSS_at_last_prediction_timestep, 'max_NIHSS', normalisation_parameters_df)\n",
    "    min_NIHSS_up_to_current_timestep = reverse_normalisation(norm_min_NIHSS_up_to_current_timestep, 'min_NIHSS', normalisation_parameters_df)\n",
    "    delta_NIHSS_at_last_predicted_ts = max_NIHSS_at_last_prediction_timestep - min_NIHSS_up_to_current_timestep\n",
    "\n",
    "    # y_pred = norm_delta_NIHSS_at_last_predicted_ts\n",
    "    y_pred = delta_NIHSS_at_last_predicted_ts\n",
    "    y_pred_binary = delta_NIHSS_at_last_predicted_ts >= 4\n",
    "\n",
    "    timestep_df = pd.DataFrame({'timestep': [ts] * len(y_true_at_evaluated_ts),\n",
    "                                        'prediction': y_pred,\n",
    "                                        'true_label': y_true_at_evaluated_ts})\n",
    "    overall_prediction_df = pd.concat([overall_prediction_df, timestep_df])\n",
    "\n",
    "    timesteps.append(ts)\n",
    "    n_pos_samples.append(np.sum(y_true_at_evaluated_ts))\n",
    "    accuracy_scores.append(accuracy_score(y_true_at_evaluated_ts, y_pred_binary))\n",
    "\n",
    "    if len(np.unique(y_true_at_evaluated_ts)) == 1:\n",
    "        roc_scores.append(np.nan)\n",
    "        auprc_scores.append(np.nan)\n",
    "        mcc_scores.append(np.nan)\n",
    "    else:\n",
    "        roc_scores.append(roc_auc_score(y_true_at_evaluated_ts, y_pred))\n",
    "        auprc_scores.append(average_precision_score(y_true_at_evaluated_ts, y_pred))\n",
    "        mcc_scores.append(matthews_corrcoef(y_true_at_evaluated_ts, y_pred_binary))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ad8fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_prediction_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ddeb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure true_label is binary\n",
    "overall_prediction_df['true_label'] = overall_prediction_df['true_label'].astype(int)\n",
    "# Ensure prediction is a continuous value between 0 and 1\n",
    "overall_prediction_df['prediction'] = overall_prediction_df['prediction'].astype(float)\n",
    "\n",
    "\n",
    "# compute overall metrics\n",
    "overall_results_df = pd.DataFrame({'overall_roc': roc_auc_score(overall_prediction_df.true_label,\n",
    "                                                                    overall_prediction_df.prediction),\n",
    "                                'overall_auprc': average_precision_score(overall_prediction_df.true_label,\n",
    "                                                                        overall_prediction_df.prediction),\n",
    "                                'overall_mcc': matthews_corrcoef(overall_prediction_df.true_label,\n",
    "                                                                    overall_prediction_df.prediction >= 4),\n",
    "                                'overall_accuracy': accuracy_score(overall_prediction_df.true_label,\n",
    "                                                                    overall_prediction_df.prediction >= 4),\n",
    "                                'n_pos_samples': np.sum(overall_prediction_df.true_label),\n",
    "                                'n_samples': len(overall_prediction_df),\n",
    "                                'cv_fold': model_config['best_cv_fold']\n",
    "                            }, index=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cb3cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0184a596",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_results_df = pd.DataFrame({'median_roc': np.nanmedian(roc_scores),\n",
    "                                        'median_auprc': np.nanmedian(auprc_scores),\n",
    "                                        'median_mcc': np.nanmedian(mcc_scores),\n",
    "                                       'median_accuracy': np.nanmedian(accuracy_scores),\n",
    "                                       'n_pos_samples': np.nanmedian(n_pos_samples),\n",
    "                                   }, index=[0])\n",
    "\n",
    "median_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbd0e42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opsum",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

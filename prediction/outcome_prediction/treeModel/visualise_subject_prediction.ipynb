{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Interactive visualisation of the prediction for a single subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T09:54:19.172089Z",
     "start_time": "2023-04-10T09:54:19.169437Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randint\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from preprocessing.preprocessing_tools.normalisation.reverse_normalisation import reverse_normalisation\n",
    "from prediction.utils.shap_helper_functions import check_shap_version_compatibility\n",
    "from prediction.utils.utils import flatten\n",
    "from prediction.outcome_prediction.data_loading.data_loader import load_data\n",
    "from prediction.utils.utils import aggregate_features_over_time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from prediction.outcome_prediction.data_loading.data_formatting import format_to_2d_table_with_time, \\\n",
    "    link_patient_id_to_outcome, features_to_numpy, numpy_to_lookup_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T09:35:49.689533Z",
     "start_time": "2023-04-10T09:35:49.686935Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Shap values require very specific versions\n",
    "check_shap_version_compatibility()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T09:37:30.793061Z",
     "start_time": "2023-04-10T09:37:30.788946Z"
    }
   },
   "outputs": [],
   "source": [
    "features_path = '/Users/jk1/temp/opsum_prepro_output/gsu_prepro_01012023_233050/preprocessed_features_01012023_233050.csv'\n",
    "labels_path = '/Users/jk1/temp/opsum_prepro_output/gsu_prepro_01012023_233050/preprocessed_outcomes_01012023_233050.csv'\n",
    "normalisation_parameters_path = '/Users/jk1/temp/opsum_prepro_output/gsu_prepro_01012023_233050/logs_01012023_233050/normalisation_parameters.csv'\n",
    "shap_over_time_path = '/Users/jk1/temp/opsum_prediction_output/linear_72h_xgb/with_feature_aggregration/testing/tree_explainer_shap_values_over_ts.pkl'\n",
    "predictions_over_time_path = '/Users/jk1/temp/opsum_prediction_output/linear_72h_xgb/with_feature_aggregration/testing/predictions_over_timesteps.pkl'\n",
    "out_dir = '/Users/jk1/Downloads'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T16:19:12.817016Z",
     "start_time": "2023-04-10T16:19:12.808702Z"
    }
   },
   "outputs": [],
   "source": [
    "outcome = '3M mRS 0-2'\n",
    "test_size = 0.2\n",
    "seed = 42\n",
    "n_splits = 5\n",
    "moving_average = False\n",
    "n_time_steps = 72\n",
    "total_n_features = 84"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T09:37:31.188876Z",
     "start_time": "2023-04-10T09:37:31.185229Z"
    }
   },
   "outputs": [],
   "source": [
    "n_features = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T10:00:54.015053Z",
     "start_time": "2023-04-10T10:00:53.731329Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(shap_over_time_path, 'rb') as handle:\n",
    "    shap_values_over_time = pickle.load(handle)\n",
    "shap_values_over_time = np.array(shap_values_over_time)\n",
    "normalisation_parameters_df = pd.read_csv(normalisation_parameters_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T09:58:27.573183Z",
     "start_time": "2023-04-10T09:58:27.561692Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(predictions_over_time_path, 'rb') as handle:\n",
    "    predictions_over_time = pickle.load(handle)\n",
    "predictions_over_time = np.array(predictions_over_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T09:55:18.416153Z",
     "start_time": "2023-04-10T09:54:24.514153Z"
    }
   },
   "outputs": [],
   "source": [
    "X, y = format_to_2d_table_with_time(feature_df_path=features_path, outcome_df_path=labels_path,\n",
    "                                    outcome=outcome)\n",
    "\n",
    "# Reduce every patient to a single outcome (to avoid duplicates)\n",
    "all_pids_with_outcome = link_patient_id_to_outcome(y, outcome)\n",
    "pid_train, pid_test, y_pid_train, y_pid_test = train_test_split(all_pids_with_outcome.patient_id.tolist(),\n",
    "                                                                all_pids_with_outcome.outcome.tolist(),\n",
    "                                                                stratify=all_pids_with_outcome.outcome.tolist(),\n",
    "                                                                test_size=test_size,\n",
    "                                                                random_state=seed)\n",
    "# Preprocess overall train data\n",
    "train_X_df = X[X.patient_id.isin(pid_train)]\n",
    "train_y_df = y[y.patient_id.isin(pid_train)]\n",
    "train_X_np = features_to_numpy(train_X_df,\n",
    "                               ['case_admission_id', 'relative_sample_date_hourly_cat', 'sample_label', 'value'])\n",
    "train_y_np = np.array([train_y_df[train_y_df.case_admission_id == cid].outcome.values[0] for cid in\n",
    "                       train_X_np[:, 0, 0, 0]]).astype('float32')\n",
    "train_X_np = train_X_np[:, :, :, -1].astype('float32')\n",
    "\n",
    "\n",
    "# Preprocess overall test data\n",
    "test_X_df = X[X.patient_id.isin(pid_test)]\n",
    "test_y_df = y[y.patient_id.isin(pid_test)]\n",
    "test_X_np = features_to_numpy(test_X_df,\n",
    "                              ['case_admission_id', 'relative_sample_date_hourly_cat', 'sample_label', 'value'])\n",
    "test_y_np = np.array([test_y_df[test_y_df.case_admission_id == cid].outcome.values[0] for cid in\n",
    "                      test_X_np[:, 0, 0, 0]]).astype('float32')\n",
    "# create look-up table for case_admission_ids, sample_labels and relative_sample_date_hourly_cat\n",
    "test_features_lookup_table = numpy_to_lookup_table(test_X_np)\n",
    "# Remove the case_admission_id, sample_label, and time_step_label columns from the data\n",
    "test_X_np = test_X_np[:, :, :, -1].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T09:45:21.175972Z",
     "start_time": "2023-04-10T09:45:21.082502Z"
    }
   },
   "outputs": [],
   "source": [
    "X_test, y_test = aggregate_features_over_time(test_X_np, test_y_np, moving_average=moving_average)\n",
    "X_test = X_test.reshape(-1, n_time_steps, X_test.shape[-1]).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T16:21:05.862569Z",
     "start_time": "2023-04-10T16:21:05.856413Z"
    }
   },
   "outputs": [],
   "source": [
    "original_features = list(test_features_lookup_table['sample_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T16:21:06.376831Z",
     "start_time": "2023-04-10T16:21:06.370086Z"
    }
   },
   "outputs": [],
   "source": [
    "avg_feature_names = [f'avg_{item}' for item in list(test_features_lookup_table['sample_label'])]\n",
    "min_feature_names = [f'min_{item}' for item in list(test_features_lookup_table['sample_label'])]\n",
    "max_feature_names = [f'max_{item}' for item in list(test_features_lookup_table['sample_label'])]\n",
    "\n",
    "feature_names = flatten([original_features, avg_feature_names, min_feature_names, max_feature_names])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T09:56:47.276109Z",
     "start_time": "2023-04-10T09:55:18.420661Z"
    }
   },
   "outputs": [],
   "source": [
    "non_normalised_train_X_df = reverse_normalisation(train_X_df, normalisation_parameters_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Choose subject and load prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T16:13:55.075538Z",
     "start_time": "2023-04-10T16:13:55.069691Z"
    }
   },
   "outputs": [],
   "source": [
    "subj = randint(0, len(test_X_np))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T16:27:16.000165Z",
     "start_time": "2023-04-10T16:27:15.990211Z"
    }
   },
   "outputs": [],
   "source": [
    "subj = 182"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T16:27:16.349209Z",
     "start_time": "2023-04-10T16:27:16.339728Z"
    }
   },
   "outputs": [],
   "source": [
    "print(subj, predictions_over_time[-1,subj])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T16:27:44.558436Z",
     "start_time": "2023-04-10T16:27:44.543317Z"
    }
   },
   "outputs": [],
   "source": [
    "subj_pred_over_ts = predictions_over_time[:,subj]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Plot overall subject prediction & explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T16:27:45.340198Z",
     "start_time": "2023-04-10T16:27:45.319187Z"
    }
   },
   "outputs": [],
   "source": [
    "shap_values_over_time.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T16:27:45.793602Z",
     "start_time": "2023-04-10T16:27:45.789013Z"
    }
   },
   "outputs": [],
   "source": [
    "np.squeeze(shap_values_over_time[-1])[subj].argsort()[-n_features:][::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T16:27:46.322926Z",
     "start_time": "2023-04-10T16:27:46.316680Z"
    }
   },
   "outputs": [],
   "source": [
    "n_features = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T16:27:47.298171Z",
     "start_time": "2023-04-10T16:27:46.765316Z"
    }
   },
   "outputs": [],
   "source": [
    "from prediction.utils.visualisation_helper_functions import reverse_normalisation_for_subj\n",
    "\n",
    "# plot a bar plot showing impact of most important features on the prediction across all n_time_steps\n",
    "# find index of 3 features with biggest positive shap impart\n",
    "selected_positive_features = np.squeeze(shap_values_over_time[-1])[subj].argsort()[-n_features:][::-1]\n",
    "\n",
    "# find index of 3 features with biggest negative shap impart\n",
    "selected_negative_features = np.squeeze(shap_values_over_time[-1])[subj].argsort()[:n_features][::-1]\n",
    "\n",
    "selected_features = np.concatenate((selected_positive_features, selected_negative_features))\n",
    "\n",
    "fig1 = plt.figure(figsize=(15,5))\n",
    "ax1 = fig1.add_subplot(121)\n",
    "ax = sns.barplot(y=np.array(feature_names)[selected_features], x=np.squeeze(shap_values_over_time[-1])[subj][selected_features], palette=\"RdBu_r\")\n",
    "ax.title.set_text(f'SHAP values for subj {subj} ')\n",
    "\n",
    "non_norm_subj_df = reverse_normalisation_for_subj(pd.DataFrame(data=test_X_np[subj], columns = original_features), normalisation_parameters_df)\n",
    "# display median of original feature value (and not aggregation) - therefore modulo is taken\n",
    "median_norm_feature_df = non_norm_subj_df.median(axis=0)[selected_features % total_n_features]\n",
    "\n",
    "ax2 = fig1.add_subplot(122)\n",
    "font_size=12\n",
    "bbox=[0, 0, 1, 1]\n",
    "ax2.axis('off')\n",
    "cell_text = []\n",
    "for row in range(len(median_norm_feature_df)):\n",
    "    cell_text.append([median_norm_feature_df.iloc[row].astype(str)])\n",
    "mpl_table = ax2.table(cellText = cell_text, rowLabels = median_norm_feature_df.index, bbox=bbox, colLabels=['Normalised value'], cellLoc='center', colLoc='center', loc='center')\n",
    "mpl_table.auto_set_font_size(False)\n",
    "mpl_table.set_fontsize(font_size)\n",
    "\n",
    "fig1.set_tight_layout(True)\n",
    "# set figure title\n",
    "fig1.suptitle(f'Explanation of prediction for subj {subj} with a probability of good outcome of {subj_pred_over_ts[-1]:.2f}', fontsize=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T16:27:47.692450Z",
     "start_time": "2023-04-10T16:27:47.671559Z"
    }
   },
   "outputs": [],
   "source": [
    "# fig1.savefig(os.path.join(out_dir, 'final_prediction.png'), dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Plot relevant features in relation to training population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T16:28:01.620159Z",
     "start_time": "2023-04-10T16:27:54.653533Z"
    }
   },
   "outputs": [],
   "source": [
    "fig2 = plt.figure(figsize=(15, 12))\n",
    "plt.subplots_adjust(hspace=0.2)\n",
    "plt.suptitle(\"Selected features\", fontsize=18, y=0.99, x=0.52, horizontalalignment='center')\n",
    "\n",
    "# set number of columns (use 3 to demonstrate the change)\n",
    "ncols = 3\n",
    "# calculate number of rows\n",
    "nrows = len(selected_features) // ncols + (len(selected_features) % ncols > 0)\n",
    "\n",
    "# loop through the length of features and keep track of index\n",
    "for n, feature in enumerate(selected_features):\n",
    "    # add a new subplot iteratively using nrows and cols\n",
    "    ax = plt.subplot(nrows, ncols, n + 1)\n",
    "\n",
    "    temp_pop_df = non_normalised_train_X_df[non_normalised_train_X_df.sample_label == original_features[feature % total_n_features]]\n",
    "    sns.histplot(temp_pop_df.value, ax=ax)\n",
    "    plt.scatter(median_norm_feature_df[original_features[feature % total_n_features]], 0, marker='o', s=500)\n",
    "    if (n % ncols) == 1:\n",
    "        if n <= len(selected_features) / 2:\n",
    "            ax.set_title(r\"$\\bf{Positive\\ features}$\" +f'\\n\\n{original_features[feature % total_n_features]}')\n",
    "        else:\n",
    "            ax.set_title(r\"$\\bf{Negative\\ features}$\" + f'\\n\\n{original_features[feature % total_n_features]}')\n",
    "\n",
    "    else:\n",
    "        ax.set_title(original_features[feature % total_n_features])\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T16:28:01.624143Z",
     "start_time": "2023-04-10T16:28:01.620818Z"
    }
   },
   "outputs": [],
   "source": [
    "# fig2.savefig(os.path.join(out_dir, 'features_histogram_comparison.png'), dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Plot evolution of prediction & explanation over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T16:28:01.628950Z",
     "start_time": "2023-04-10T16:28:01.626487Z"
    }
   },
   "outputs": [],
   "source": [
    "overall_prevailing_features = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T16:28:02.057653Z",
     "start_time": "2023-04-10T16:28:01.642324Z"
    }
   },
   "outputs": [],
   "source": [
    "cumulative_shap_values_over_time = np.array([shap_values_over_time[ts].sum(axis=1) for ts in range(n_time_steps)])\n",
    "\n",
    "# find index of 3 features with biggest positive shap impart & index of 3 features with biggest negative shap impart\n",
    "if overall_prevailing_features:\n",
    "    # prevailing features over cumulative time\n",
    "    selected_negative_features = cumulative_shap_values_over_time[:, subj].argsort()[:n_features][::-1]\n",
    "    selected_positive_features = cumulative_shap_values_over_time[:, subj].argsort()[-n_features:][::-1]\n",
    "else:\n",
    "    # prevailing features at last timepoint\n",
    "    selected_positive_features = np.squeeze(shap_values_over_time[-1])[subj].argsort()[-n_features:][::-1]\n",
    "    selected_negative_features = np.squeeze(shap_values_over_time[-1])[subj].argsort()[:n_features][::-1]\n",
    "\n",
    "selected_features = np.concatenate((selected_positive_features, selected_negative_features))\n",
    "\n",
    "fig3 = plt.figure(figsize=(15,10))\n",
    "\n",
    "k=0.05\n",
    "alpha=0.3\n",
    "\n",
    "timestep_axis = np.array(range(n_time_steps))\n",
    "\n",
    "positive_color_palette = sns.color_palette(\"mako\", n_colors=len(selected_positive_features))\n",
    "negative_color_palette = sns.color_palette(\"flare_r\", n_colors=len(selected_negative_features))\n",
    "\n",
    "timestep_axis = np.array(range(n_time_steps))\n",
    "ax = sns.lineplot(x=timestep_axis, y=subj_pred_over_ts, label='probability', linewidth = 2)\n",
    "\n",
    "\n",
    "pos_baseline = subj_pred_over_ts\n",
    "neg_baseline = subj_pred_over_ts\n",
    "pos_count = 0\n",
    "neg_count = 0\n",
    "for i, feature in enumerate(selected_features):\n",
    "    subj_feature_shap_value_over_time = shap_values_over_time[:, subj, feature]\n",
    "    positive_portion = (subj_feature_shap_value_over_time > 0)\n",
    "    negative_portion = (subj_feature_shap_value_over_time < 0)\n",
    "\n",
    "    pos_function = subj_feature_shap_value_over_time.copy()\n",
    "    pos_function[negative_portion] = 0\n",
    "\n",
    "    neg_function = subj_feature_shap_value_over_time.copy()\n",
    "    neg_function[positive_portion] = 0\n",
    "\n",
    "    if feature in selected_positive_features:\n",
    "        feature_color = positive_color_palette[pos_count]\n",
    "        pos_count += 1\n",
    "    else:\n",
    "        feature_color = negative_color_palette[neg_count]\n",
    "        neg_count += 1\n",
    "\n",
    "    positive_feature = pos_baseline + k * pos_function\n",
    "    ax.fill_between(timestep_axis, pos_baseline, positive_feature, color=feature_color, alpha=alpha, label=feature_names[feature])\n",
    "    pos_baseline = positive_feature\n",
    "\n",
    "    negative_feature = neg_baseline + k * neg_function\n",
    "    ax.fill_between(timestep_axis, negative_feature, neg_baseline, color=feature_color, alpha=alpha)\n",
    "    neg_baseline = negative_feature\n",
    "\n",
    "ax.legend(fontsize='x-large')\n",
    "\n",
    "ax.set_title(f'Predictions for subject {subj} of test set along time', fontsize=20)\n",
    "ax.set_xlabel('Time from admission (hours)', fontsize=15)\n",
    "ax.set_ylabel('Probability of favorable outcome', fontsize=15)\n",
    "\n",
    "# ax.set_ylim(0,1)\n",
    "\n",
    "plt.plot()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig3.savefig(os.path.join(out_dir, 'prediction_over_time.png'), dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Plot selected features over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T16:24:38.882833Z",
     "start_time": "2023-04-10T16:24:37.031263Z"
    }
   },
   "outputs": [],
   "source": [
    "fig4 = plt.figure(figsize=(15, 12))\n",
    "plt.subplots_adjust(hspace=0.2)\n",
    "plt.suptitle(\"Selected features\", fontsize=18, y=0.99, x=0.52, horizontalalignment='center')\n",
    "\n",
    "# set number of columns (use 3 to demonstrate the change)\n",
    "ncols = 3\n",
    "# calculate number of rows\n",
    "nrows = len(selected_features) // ncols + (len(selected_features) % ncols > 0)\n",
    "\n",
    "pos_count = 0\n",
    "neg_count = 0\n",
    "# loop through the length of features and keep track of index\n",
    "for n, feature in enumerate(selected_features):\n",
    "    # add a new subplot iteratively using nrows and cols\n",
    "    ax = plt.subplot(nrows, ncols, n + 1)\n",
    "\n",
    "    if feature in selected_positive_features:\n",
    "        feature_color = positive_color_palette[pos_count]\n",
    "        pos_count += 1\n",
    "    else:\n",
    "        feature_color = negative_color_palette[neg_count]\n",
    "        neg_count += 1\n",
    "    sns.lineplot(y=original_features[feature % total_n_features], x='index', data=non_norm_subj_df.reset_index(), color=feature_color, ax=ax)\n",
    "\n",
    "    if (n % ncols) == 1:\n",
    "        if n <= len(selected_features) / 2:\n",
    "            ax.set_title(r\"$\\bf{Positive\\ features}$\" +f'\\n\\n{original_features[feature % total_n_features]}')\n",
    "        else:\n",
    "            ax.set_title(r\"$\\bf{Negative\\ features}$\" + f'\\n\\n{original_features[feature % total_n_features]}')\n",
    "    else:\n",
    "        ax.set_title(feature_names[feature])\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig4.savefig(os.path.join(out_dir, 'features_over_time.png'), dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Plot contribution of a specific feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T16:33:53.225583Z",
     "start_time": "2023-04-10T16:33:53.203123Z"
    }
   },
   "outputs": [],
   "source": [
    "np.array(original_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T16:35:29.405551Z",
     "start_time": "2023-04-10T16:35:29.400344Z"
    }
   },
   "outputs": [],
   "source": [
    "selected_features = [\"median_mean_blood_pressure\", \"median_diastolic_blood_pressure\", \"median_systolic_blood_pressure\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T16:35:30.067589Z",
     "start_time": "2023-04-10T16:35:30.063695Z"
    }
   },
   "outputs": [],
   "source": [
    "selected_features_idx = [np.where(np.array(original_features) == selected_feature)[0][0] for selected_feature in selected_features]\n",
    "selected_features_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_shap_values_over_time = np.array([shap_values_over_time[ts][0].sum(axis=1) for ts in range(n_time_steps)])\n",
    "subj_pred_over_ts = predictions_over_time[:,subj]\n",
    "\n",
    "fig3 = plt.figure(figsize=(15,10))\n",
    "\n",
    "k=1\n",
    "alpha=0.3\n",
    "\n",
    "timestep_axis = np.array(range(n_time_steps))\n",
    "\n",
    "positive_color_palette = sns.color_palette(\"mako\", n_colors=len(selected_positive_features))\n",
    "negative_color_palette = sns.color_palette(\"flare_r\", n_colors=len(selected_negative_features))\n",
    "\n",
    "timestep_axis = np.array(range(n_time_steps))\n",
    "ax = sns.lineplot(x=timestep_axis, y=subj_pred_over_ts, label='probability', linewidth = 2)\n",
    "ax2 = ax.twinx()\n",
    "\n",
    "\n",
    "pos_baseline = subj_pred_over_ts\n",
    "neg_baseline = subj_pred_over_ts\n",
    "pos_count, neg_count = 0, 0\n",
    "for i, feature in enumerate(selected_features_idx):\n",
    "    subj_cumulative_shap_value_over_time = cumulative_shap_values_over_time[:, subj, feature]\n",
    "    positive_portion = (subj_cumulative_shap_value_over_time > 0)\n",
    "    negative_portion = (subj_cumulative_shap_value_over_time < 0)\n",
    "\n",
    "    pos_function = subj_cumulative_shap_value_over_time.copy()\n",
    "    pos_function[negative_portion] = 0\n",
    "\n",
    "    neg_function = subj_cumulative_shap_value_over_time.copy()\n",
    "    neg_function[positive_portion] = 0\n",
    "\n",
    "    if sum(subj_cumulative_shap_value_over_time) > 0:\n",
    "        feature_color = positive_color_palette[pos_count]\n",
    "        pos_count += 1\n",
    "    else:\n",
    "        feature_color = negative_color_palette[neg_count]\n",
    "        neg_count += 1\n",
    "\n",
    "    positive_feature = pos_baseline + k * pos_function\n",
    "    ax.fill_between(timestep_axis, pos_baseline, positive_feature, color=feature_color, alpha=alpha, label=features[feature])\n",
    "    pos_baseline = positive_feature\n",
    "\n",
    "    negative_feature = neg_baseline + k * neg_function\n",
    "    ax.fill_between(timestep_axis, negative_feature, neg_baseline, color=feature_color, alpha=alpha)\n",
    "    neg_baseline = negative_feature\n",
    "\n",
    "    sns.scatterplot(y=features[feature], x='index', data=non_norm_subj_df.reset_index(), ax=ax2, legend=False, color=feature_color)\n",
    "\n",
    "ax.legend(fontsize='x-large')\n",
    "\n",
    "ax.set_title(f'Predictions for subject {subj} of test set along time', fontsize=20)\n",
    "ax.set_xlabel('Time from admission (hours)', fontsize=15)\n",
    "ax.set_ylabel('Probability of favorable outcome', fontsize=15)\n",
    "\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig4 = plt.figure(figsize=(15, 12))\n",
    "plt.subplots_adjust(hspace=0.2)\n",
    "plt.suptitle(\"Selected features\", fontsize=18, y=0.99, x=0.52, horizontalalignment='center')\n",
    "\n",
    "# set number of columns (use 3 to demonstrate the change)\n",
    "ncols = 3\n",
    "# calculate number of rows\n",
    "nrows = len(selected_features_idx) // ncols + (len(selected_features_idx) % ncols > 0)\n",
    "\n",
    "pos_count = 0\n",
    "neg_count = 0\n",
    "# loop through the length of features and keep track of index\n",
    "for n, feature in enumerate(selected_features_idx):\n",
    "    # add a new subplot iteratively using nrows and cols\n",
    "    ax = plt.subplot(nrows, ncols, n + 1)\n",
    "\n",
    "    if sum(subj_cumulative_shap_value_over_time) > 0:\n",
    "        feature_color = positive_color_palette[pos_count]\n",
    "        pos_count += 1\n",
    "    else:\n",
    "        feature_color = negative_color_palette[neg_count]\n",
    "        neg_count += 1\n",
    "    sns.lineplot(y=features[feature], x='index', data=non_norm_subj_df.reset_index(), color=feature_color, ax=ax)\n",
    "\n",
    "    ax.set_title(features[feature])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values_over_time[-1][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "auto=False\n",
    "\n",
    "X_test_2D = test_X_np.reshape(-1,n_channels)\n",
    "shap_values_2D = shap_values_over_time[-1][0].reshape(-1,n_channels)\n",
    "x_test_2d = pd.DataFrame(data=X_test_2D, columns = features)\n",
    "\n",
    "for n, feature in enumerate(selected_features_idx):\n",
    "    if auto == True:\n",
    "        # automatic choice of interaction\n",
    "        shap.dependence_plot(features[feature], shap_values_2D, x_test_2d)\n",
    "    else:\n",
    "        shap.dependence_plot(features[feature], shap_values_2D, x_test_2d, interaction_index=\"median_NIHSS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "\n",
    "import shap\n",
    "import os\n",
    "\n",
    "from prediction.outcome_prediction.LSTM.testing.shap_helper_functions import check_shap_version_compatibility\n",
    "from prediction.utils.scoring import precision, recall, matthews\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from prediction.outcome_prediction.data_loading.data_formatting import format_to_2d_table_with_time\n",
    "import torch as ch\n",
    "import pytorch_lightning as pl\n",
    "import torchmetrics\n",
    "from torchmetrics import AUROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shap values require very specific versions\n",
    "check_shap_version_compatibility()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_path = '/Users/jk1/temp/opsum_prepro_output/gsu_prepro_01012023_233050/preprocessed_features_01012023_233050.csv'\n",
    "labels_path = '/Users/jk1/temp/opsum_prepro_output/gsu_prepro_01012023_233050/preprocessed_outcomes_01012023_233050.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config_path = '/Users/jk1/Downloads/params_opsum_transformer_20230306_221654.json'\n",
    "model_path = '/Users/jk1/Downloads/opsum_transformer_20230306_221654_epoch=15_val_auroc=0.9012.ckpt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model config from json\n",
    "model_config = json.load(open(model_config_path, 'r'))\n",
    "model_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "X, y = format_to_2d_table_with_time(feature_df_path=features_path, outcome_df_path=labels_path,\n",
    "                                    outcome=model_config['outcome'])\n",
    "\n",
    "n_time_steps = X.relative_sample_date_hourly_cat.max() + 1\n",
    "n_channels = X.sample_label.unique().shape[0]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from prediction.outcome_prediction.data_loading.data_formatting import features_to_numpy, \\\n",
    "    link_patient_id_to_outcome, numpy_to_lookup_table\n",
    "\n",
    "# Reduce every patient to a single outcome (to avoid duplicates)\n",
    "all_pids_with_outcome = link_patient_id_to_outcome(y, model_config['outcome'])\n",
    "pid_train, pid_test, y_pid_train, y_pid_test = train_test_split(all_pids_with_outcome.patient_id.tolist(),\n",
    "                                                                all_pids_with_outcome.outcome.tolist(),\n",
    "                                                                stratify=all_pids_with_outcome.outcome.tolist(),\n",
    "                                                                test_size=model_config['test_size'],\n",
    "                                                                random_state=model_config['seed'])\n",
    "\n",
    "test_X_df = X[X.patient_id.isin(pid_test)]\n",
    "test_y_df = y[y.patient_id.isin(pid_test)]\n",
    "train_X_df = X[X.patient_id.isin(pid_train)]\n",
    "train_y_df = y[y.patient_id.isin(pid_train)]\n",
    "\n",
    "train_X_np = features_to_numpy(train_X_df,\n",
    "                               ['case_admission_id', 'relative_sample_date_hourly_cat', 'sample_label', 'value'])\n",
    "test_X_np = features_to_numpy(test_X_df,\n",
    "                              ['case_admission_id', 'relative_sample_date_hourly_cat', 'sample_label', 'value'])\n",
    "train_y_np = np.array([train_y_df[train_y_df.case_admission_id == cid].outcome.values[0] for cid in\n",
    "                       train_X_np[:, 0, 0, 0]]).astype('float32')\n",
    "test_y_np = np.array([test_y_df[test_y_df.case_admission_id == cid].outcome.values[0] for cid in\n",
    "                      test_X_np[:, 0, 0, 0]]).astype('float32')\n",
    "\n",
    "# create look-up table for case_admission_ids, sample_labels and relative_sample_date_hourly_cat\n",
    "test_features_lookup_table = numpy_to_lookup_table(test_X_np)\n",
    "train_features_lookup_table = numpy_to_lookup_table(train_X_np)\n",
    "\n",
    "# Remove the case_admission_id, sample_label, and time_step_label columns from the data\n",
    "test_X_np = test_X_np[:, :, :, -1].astype('float32')\n",
    "train_X_np = train_X_np[:, :, :, -1].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the LightningModule\n",
    "class LitModel(pl.LightningModule):\n",
    "    def __init__(self, model, lr, wd, train_noise):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.lr = lr\n",
    "        self.wd = wd\n",
    "        self.train_noise = train_noise\n",
    "        self.criterion = ch.nn.BCEWithLogitsLoss()\n",
    "        self.train_auroc = AUROC(task=\"binary\")\n",
    "        self.val_auroc = AUROC(task=\"binary\")\n",
    "\n",
    "    def training_step(self, batch, batch_idx, mode='train'):\n",
    "        x, y = batch\n",
    "        if self.train_noise != 0:\n",
    "            x = x + ch.randn_like(x) * self.train_noise\n",
    "        predictions = self.model(x).squeeze().ravel()\n",
    "        y = y.unsqueeze(1).repeat(1, x.shape[1]).ravel()\n",
    "        loss = self.criterion(predictions, y.float()).ravel()\n",
    "        self.train_auroc(ch.sigmoid(predictions.ravel()), y.ravel())\n",
    "        self.log(\"train_auroc\", self.train_auroc, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx, mode='train'):\n",
    "        x, y = batch\n",
    "        predictions = self.model(x).squeeze().ravel()\n",
    "        y = y.unsqueeze(1).repeat(1, x.shape[1]).ravel()\n",
    "        loss = self.criterion(predictions, y.float()).ravel()\n",
    "        self.val_auroc(ch.sigmoid(predictions.ravel()), y.ravel())\n",
    "        self.log(\"val_auroc\", self.val_auroc, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def predict_step(self, x):\n",
    "        predictions = self.model(x).squeeze().ravel()\n",
    "        return predictions\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = ch.optim.Adam(self.parameters(), lr=self.lr, weight_decay=self.wd)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prediction.outcome_prediction.Transformer.architecture import OPSUMTransformer\n",
    "\n",
    "ff_dim = model_config['ff_factor'] * model_config['model_dim']\n",
    "\n",
    "\n",
    "model = OPSUMTransformer(\n",
    "            input_dim=84,\n",
    "            num_layers=model_config['num_layers'],\n",
    "            model_dim=model_config['model_dim'],\n",
    "            dropout=model_config['dropout'],\n",
    "            ff_dim=ff_dim,\n",
    "            num_heads=model_config['num_heads'],\n",
    "            num_classes=1,\n",
    "            max_dim=model_config['max_dim'],\n",
    "            pos_encode_factor=model_config['pos_encode_factor'],\n",
    "        )\n",
    "\n",
    "module = LitModel(model, model_config['lr'], model_config['weight_decay'], model_config['train_noise'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ch.load(model_path, map_location=ch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model = LitModel.load_from_checkpoint(checkpoint_path=model_path, model=model, lr=model_config['lr'], wd=model_config['weight_decay'], train_noise=model_config['train_noise'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "predict with model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model.eval()\n",
    "with ch.no_grad():\n",
    "    # y_hat = saved_model.predict_step(ch.from_numpy(test_X_np))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "y_hat_std = np.std(y_hat.numpy(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median(y_hat_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(y_hat_std), np.max(y_hat_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_sigm = ch.sigmoid(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Use the training data for deep explainer => can use fewer instances\n",
    "explainer = shap.DeepExplainer(saved_model.model, ch.from_numpy(train_X_np))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explain the testing instances (can use fewer instances)\n",
    "# explaining each prediction requires 2 * background dataset size runs\n",
    "shap_values = explainer.shap_values(ch.from_numpy(test_X_np[0:1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

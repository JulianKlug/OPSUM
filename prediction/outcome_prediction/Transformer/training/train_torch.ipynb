{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f658b6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch as ch\n",
    "import matplotlib.pyplot as plt\n",
    "import os, traceback\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import roc_auc_score, matthews_corrcoef\n",
    "import argparse\n",
    "import sys\n",
    "import os\n",
    "from functools import partial\n",
    "from torch import optim, nn, utils, Tensor\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "import pytorch_lightning as pl\n",
    "from torchmetrics import AUROC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sys.path.insert(0, '/home/guillaume/julian/OPSUM/')\n",
    "\n",
    "\n",
    "from prediction.outcome_prediction.LSTM.training.utils import initiate_log_files\n",
    "from prediction.outcome_prediction.data_loading.data_formatting import format_to_2d_table_with_time, \\\n",
    "    link_patient_id_to_outcome, features_to_numpy, numpy_to_lookup_table, feature_order_verification\n",
    "from prediction.utils.scoring import precision, matthews, recall\n",
    "from prediction.utils.utils import generate_balanced_arrays, check_data, ensure_dir, save_json\n",
    "from prediction.outcome_prediction.LSTM.LSTM import lstm_generator\n",
    "\n",
    "from prediction.outcome_prediction.Transformer.architecture import OPSUMTransformer\n",
    "\n",
    "\n",
    "def prep(features_path: str, labels_path:str, outcome:str, test_size:float,seed=0, n_splits=7):\n",
    "    ### LOAD THE DATA\n",
    "    X, y = format_to_2d_table_with_time(feature_df_path=features_path, outcome_df_path=labels_path,\n",
    "                                        outcome=outcome)\n",
    "\n",
    "    n_time_steps = X.relative_sample_date_hourly_cat.max() + 1\n",
    "    n_channels = X.sample_label.unique().shape[0]\n",
    "\n",
    "    # test if data is corrupted\n",
    "    check_data(X)\n",
    "\n",
    "    \"\"\"\n",
    "    SPLITTING DATA\n",
    "    Splitting is done by patient id (and not admission id) as in case of the rare multiple admissions per patient there\n",
    "    would be a risk of data leakage otherwise split 'pid' in TRAIN and TEST pid = unique patient_id\n",
    "    \"\"\"\n",
    "    # Reduce every patient to a single outcome (to avoid duplicates)\n",
    "    all_pids_with_outcome = link_patient_id_to_outcome(y, outcome)\n",
    "    pid_train, pid_test, y_pid_train, y_pid_test = train_test_split(all_pids_with_outcome.patient_id.tolist(),\n",
    "                                                                    all_pids_with_outcome.outcome.tolist(),\n",
    "                                                                    stratify=all_pids_with_outcome.outcome.tolist(),\n",
    "                                                                    test_size=test_size,\n",
    "                                                                    random_state=seed)\n",
    "\n",
    "    test_X = X[X.patient_id.isin(pid_test)]\n",
    "    # Here test data is not needed anymore, but for reference should be loaded as such: test_y = y[y.patient_id.isin(pid_test)]\n",
    "\n",
    "    # define K fold\n",
    "    kfold = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "\n",
    "    \n",
    "    ### TRAIN MODEL USING K-FOLD CROSS-VALIDATION\n",
    "    i = 0\n",
    "    for fold_pid_train_idx, fold_pid_val_idx in kfold.split(pid_train, y_pid_train):\n",
    "        fold_train_pidx = np.array(pid_train)[fold_pid_train_idx]\n",
    "        fold_val_pidx = np.array(pid_train)[fold_pid_val_idx]\n",
    "\n",
    "        fold_X_train_df = X.loc[X.patient_id.isin(fold_train_pidx)]\n",
    "        fold_y_train_df = y.loc[y.patient_id.isin(fold_train_pidx)]\n",
    "        fold_X_val_df = X.loc[X.patient_id.isin(fold_val_pidx)]\n",
    "        fold_y_val_df = y.loc[y.patient_id.isin(fold_val_pidx)]\n",
    "\n",
    "        fold_X_train = features_to_numpy(fold_X_train_df, ['case_admission_id', 'relative_sample_date_hourly_cat', 'sample_label', 'value'])\n",
    "        fold_X_val = features_to_numpy(fold_X_val_df, ['case_admission_id', 'relative_sample_date_hourly_cat', 'sample_label', 'value'])\n",
    "\n",
    "        fold_y_train = np.array([fold_y_train_df[fold_y_train_df.case_admission_id == cid].outcome.values[0] for cid in fold_X_train[:, 0, 0, 0]]).astype('float32')\n",
    "        fold_y_val = np.array([fold_y_val_df[fold_y_val_df.case_admission_id == cid].outcome.values[0] for cid in fold_X_val[:, 0, 0, 0]]).astype('float32')\n",
    "\n",
    "        fold_X_train = fold_X_train[:, :, :, -1].astype('float32')\n",
    "        fold_X_val = fold_X_val[:, :, :, -1].astype('float32')\n",
    "        \n",
    "        yield fold_X_train, fold_X_val, fold_y_train, fold_y_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84105841",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenarios = list(prep('/home/guillaume/julian/preprocessed_features_01012023_233050.csv', '/home/guillaume/julian/preprocessed_outcomes_01012023_233050.csv', outcome=\"3M mRS 0-2\",\n",
    "    test_size=0.2, seed=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa37cb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "ch.save(scenarios, 'data_splits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54518294",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48b632f",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa.nbytes / 2**30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37f7c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.loggers.logger import Logger\n",
    "class DictLogger(Logger):\n",
    "    \"\"\"PyTorch Lightning `dict` logger.\"\"\"\n",
    "\n",
    "    def __init__(self, version):\n",
    "        super(DictLogger, self).__init__()\n",
    "        self.metrics = []\n",
    "        self._version = version\n",
    "\n",
    "    def log_metrics(self, metrics, step=None):\n",
    "        self.metrics.append(metrics)\n",
    "\n",
    "    @property\n",
    "    def version(self):\n",
    "        return self._version\n",
    "\n",
    "    @property\n",
    "    def experiment(self):\n",
    "        \"\"\"Return the experiment object associated with this logger.\"\"\"\n",
    "\n",
    "    def log_hyperparams(self, params):\n",
    "        \"\"\"\n",
    "        Record hyperparameters.\n",
    "        Args:\n",
    "            params: :class:`~argparse.Namespace` containing the hyperparameters\n",
    "        \"\"\"\n",
    "\n",
    "    @property\n",
    "    def name(self):\n",
    "        \"\"\"Return the experiment name.\"\"\"\n",
    "        return 'optuna'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc7a9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train.reshape(-1, 84)).reshape(X_train.shape)\n",
    "X_val = scaler.transform(X_val.reshape(-1, 84)).reshape(X_val.shape)\n",
    "train_dataset = TensorDataset(ch.from_numpy(X_train).cuda(), ch.from_numpy(y_train.astype(np.int32)).cuda())\n",
    "train_loader = DataLoader(train_dataset, batch_size=256)\n",
    "val_dataset = TensorDataset(ch.from_numpy(X_val).cuda(), ch.from_numpy(y_val.astype(np.int32)).cuda())\n",
    "val_loader = DataLoader(val_dataset, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedb7f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# define any number of nn.Modules (or use your current ones)\n",
    "encoder = nn.Sequential(nn.Linear(28 * 28, 64), nn.ReLU(), nn.Linear(64, 3))\n",
    "decoder = nn.Sequential(nn.Linear(3, 64), nn.ReLU(), nn.Linear(64, 28 * 28))\n",
    "\n",
    "\n",
    "# define the LightningModule\n",
    "class LitModel(pl.LightningModule):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.criterion = ch.nn.BCEWithLogitsLoss()\n",
    "        self.train_auroc = AUROC(task=\"binary\")\n",
    "        self.val_auroc = AUROC(task=\"binary\")\n",
    "\n",
    "    def training_step(self, batch, batch_idx, mode='train'):\n",
    "        x, y = batch\n",
    "        predictions = self.model(x).squeeze().ravel()\n",
    "        y = y.unsqueeze(1).repeat(1, x.shape[1]).ravel()\n",
    "        loss = self.criterion(predictions, y.float()).ravel()\n",
    "        self.train_auroc(ch.sigmoid(predictions.ravel()), y.ravel())\n",
    "        cur_lr = self.trainer.optimizers[0].param_groups[0]['lr']\n",
    "        self.log(\"lr\", cur_lr, prog_bar=True, on_step=True)\n",
    "        self.log(\"train_auroc\", self.train_auroc, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self,batch, batch_idx, mode='train'):\n",
    "        x, y = batch\n",
    "        predictions = self.model(x).squeeze().ravel()\n",
    "        y = y.unsqueeze(1).repeat(1, x.shape[1]).ravel()\n",
    "        loss = self.criterion(predictions, y.float()).ravel()\n",
    "        self.val_auroc(ch.sigmoid(predictions.ravel()), y.ravel())\n",
    "        self.log(\"val_auroc\", self.val_auroc, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), weight_decay=0.0005)\n",
    "        return optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22faf567",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import ExponentialLR, LambdaLR\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1579a9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([x['lr'] for x in logger.metrics if 'lr' in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69e0af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([x['train_auroc'] for x in logger.metrics if 'train_auroc' in x])\n",
    "plt.plot([x['val_auroc'] for x in logger.metrics if 'val_auroc' in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3177931",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([x['train_auroc'] for x in logger.metrics if 'train_auroc' in x])\n",
    "plt.plot([x['val_auroc'] for x in logger.metrics if 'val_auroc' in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7aad71",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = OPSUMTransformer(\n",
    "    input_dim=X_train.shape[2],\n",
    "    num_layers=6,\n",
    "    model_dim=128,\n",
    "    dropout=0.99,\n",
    "    ff_dim=256,\n",
    "    num_heads=8,\n",
    "    num_classes=1,\n",
    "    max_dim=500,\n",
    "    pos_encode_factor=1e-3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709e7579",
   "metadata": {},
   "outputs": [],
   "source": [
    "module = LitModel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5d6c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = DictLogger(1)\n",
    "lr_monitor = LearningRateMonitor(logging_interval='step')\n",
    "trainer = pl.Trainer(accelerator='gpu', devices=1, max_epochs=50,\n",
    "                     callbacks=[lr_monitor], logger=logger)\n",
    "trainer.fit(model=module, train_dataloaders=train_loader, val_dataloaders=val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62204e2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1708d01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.cuda()(ch.from_numpy(X_train).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b14e444",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.prod(X_train.shape) * 4 / 2**20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b605b348",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_average(features, labels):\n",
    "    avg_features = np.cumsum(features, 1) / (np.arange(1, features.shape[1] + 1)[None, :, None])\n",
    "    min_features = np.minimum.accumulate(features, 1)\n",
    "    max_features = np.maximum.accumulate(features, 1)\n",
    "    all_features = np.concatenate([features, avg_features, min_features, max_features], 2)\n",
    "    all_features = all_features.reshape(-1, all_features.shape[-1])\n",
    "    labels = labels[:, None].repeat(72, 1).ravel()\n",
    "    print(labels.shape)\n",
    "    return all_features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d557dc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = XGBClassifier(n_estimators=65, learning_rate=0.1, reg_lambda=50, alpha=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12ef59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_features_train, flat_labels_train = prep_average(X_train, y_train)\n",
    "flat_features_val, flat_labels_val = prep_average(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d74472e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time classifier.fit(flat_features_train, flat_labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea505a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_train = classifier.predict_proba(flat_features_train)[:, 1].reshape(-1, 72).T\n",
    "prediction_val = classifier.predict_proba(flat_features_val)[:, 1].reshape(-1, 72).T\n",
    "scores_train = []\n",
    "scores_val = []\n",
    "for time in range(72):\n",
    "    scores_train.append(roc_auc_score(y_train, prediction_train[time]))\n",
    "    scores_val.append(roc_auc_score(y_val, prediction_val[time]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8f9bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(flat_labels_val, prediction_val.T.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7d5421",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(scores_val, label='Val set')\n",
    "plt.gca().set_ylabel('ROC AUC')\n",
    "plt.xlabel('Hours from admission')\n",
    "plt.axhline(roc_auc_score(flat_labels_val, prediction_val.T.ravel()), label='average over time')\n",
    "plt.plot(scores_train, label='Test set')\n",
    "plt.grid()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae94a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fa59d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f40ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, c  = roc_curve(flat_labels_val, prediction_val.T.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5327b3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(a, b)\n",
    "plt.plot(1 - b, 1 - a)\n",
    "plt.grid()\n",
    "plt.gca().set_aspect('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4686f799",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1763970",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = MLPClassifier((128, 128, 64), learning_rate='adaptive', alpha=12.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6394e96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time model2.fit(flat_features_train, flat_labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d1bab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_train = model2.predict_proba(flat_features_train)[:, 1].reshape(-1, 72).T\n",
    "prediction_val = model2.predict_proba(flat_features_val)[:, 1].reshape(-1, 72).T\n",
    "scores_train = []\n",
    "scores_val = []\n",
    "for time in range(72):\n",
    "    scores_train.append(roc_auc_score(y_train, prediction_train[time]))\n",
    "    scores_val.append(roc_auc_score(y_val, prediction_val[time]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4549e575",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(flat_labels_val, prediction_val.T.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a4e179",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(scores_val, label='Val set')\n",
    "plt.gca().set_ylabel('ROC AUC')\n",
    "plt.xlabel('Hours from admission')\n",
    "plt.axhline(roc_auc_score(flat_labels_val, prediction_val.T.ravel()), label='average over time')\n",
    "plt.plot(scores_train, label='Train set')\n",
    "plt.grid()\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

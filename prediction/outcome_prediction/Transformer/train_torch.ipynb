{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f658b6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch as ch\n",
    "import matplotlib.pyplot as plt\n",
    "import os, traceback\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import roc_auc_score, matthews_corrcoef\n",
    "import argparse\n",
    "import sys\n",
    "sys.path.insert(0, '/home/guillaume/julian/OPSUM/')\n",
    "\n",
    "\n",
    "from prediction.outcome_prediction.LSTM.training.utils import initiate_log_files\n",
    "from prediction.outcome_prediction.data_loading.data_formatting import format_to_2d_table_with_time, \\\n",
    "    link_patient_id_to_outcome, features_to_numpy, numpy_to_lookup_table, feature_order_verification\n",
    "from prediction.utils.scoring import precision, matthews, recall\n",
    "from prediction.utils.utils import generate_balanced_arrays, check_data, ensure_dir, save_json\n",
    "from prediction.outcome_prediction.LSTM.LSTM import lstm_generator\n",
    "\n",
    "from prediction.outcome_prediction.Transformer.architecture import OPSUMTransformer\n",
    "\n",
    "\n",
    "def prep(features_path: str, labels_path:str, outcome:str, test_size:float,seed=0, n_splits=7):\n",
    "    ### LOAD THE DATA\n",
    "    X, y = format_to_2d_table_with_time(feature_df_path=features_path, outcome_df_path=labels_path,\n",
    "                                        outcome=outcome)\n",
    "\n",
    "    n_time_steps = X.relative_sample_date_hourly_cat.max() + 1\n",
    "    n_channels = X.sample_label.unique().shape[0]\n",
    "\n",
    "    # test if data is corrupted\n",
    "    check_data(X)\n",
    "\n",
    "    \"\"\"\n",
    "    SPLITTING DATA\n",
    "    Splitting is done by patient id (and not admission id) as in case of the rare multiple admissions per patient there\n",
    "    would be a risk of data leakage otherwise split 'pid' in TRAIN and TEST pid = unique patient_id\n",
    "    \"\"\"\n",
    "    # Reduce every patient to a single outcome (to avoid duplicates)\n",
    "    all_pids_with_outcome = link_patient_id_to_outcome(y, outcome)\n",
    "    pid_train, pid_test, y_pid_train, y_pid_test = train_test_split(all_pids_with_outcome.patient_id.tolist(),\n",
    "                                                                    all_pids_with_outcome.outcome.tolist(),\n",
    "                                                                    stratify=all_pids_with_outcome.outcome.tolist(),\n",
    "                                                                    test_size=test_size,\n",
    "                                                                    random_state=seed)\n",
    "\n",
    "    test_X = X[X.patient_id.isin(pid_test)]\n",
    "    # Here test data is not needed anymore, but for reference should be loaded as such: test_y = y[y.patient_id.isin(pid_test)]\n",
    "\n",
    "    # define K fold\n",
    "    kfold = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "\n",
    "    \n",
    "    ### TRAIN MODEL USING K-FOLD CROSS-VALIDATION\n",
    "    i = 0\n",
    "    for fold_pid_train_idx, fold_pid_val_idx in kfold.split(pid_train, y_pid_train):\n",
    "        fold_train_pidx = np.array(pid_train)[fold_pid_train_idx]\n",
    "        fold_val_pidx = np.array(pid_train)[fold_pid_val_idx]\n",
    "\n",
    "        fold_X_train_df = X.loc[X.patient_id.isin(fold_train_pidx)]\n",
    "        fold_y_train_df = y.loc[y.patient_id.isin(fold_train_pidx)]\n",
    "        fold_X_val_df = X.loc[X.patient_id.isin(fold_val_pidx)]\n",
    "        fold_y_val_df = y.loc[y.patient_id.isin(fold_val_pidx)]\n",
    "\n",
    "        fold_X_train = features_to_numpy(fold_X_train_df, ['case_admission_id', 'relative_sample_date_hourly_cat', 'sample_label', 'value'])\n",
    "        fold_X_val = features_to_numpy(fold_X_val_df, ['case_admission_id', 'relative_sample_date_hourly_cat', 'sample_label', 'value'])\n",
    "\n",
    "        fold_y_train = np.array([fold_y_train_df[fold_y_train_df.case_admission_id == cid].outcome.values[0] for cid in fold_X_train[:, 0, 0, 0]]).astype('float32')\n",
    "        fold_y_val = np.array([fold_y_val_df[fold_y_val_df.case_admission_id == cid].outcome.values[0] for cid in fold_X_val[:, 0, 0, 0]]).astype('float32')\n",
    "\n",
    "        fold_X_train = fold_X_train[:, :, :, -1].astype('float32')\n",
    "        fold_X_val = fold_X_val[:, :, :, -1].astype('float32')\n",
    "        \n",
    "        return fold_X_train, fold_X_val, fold_y_train, fold_y_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84105841",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val , y_train, y_val = prep('/home/guillaume/julian/preprocessed_features_01012023_233050.csv', '/home/guillaume/julian/preprocessed_outcomes_01012023_233050.csv', outcome=\"3M mRS 0-2\",\n",
    "    test_size=0.2, seed=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068e359a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8fb28c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ch.from_numpy(X_train).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfa4c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfcf79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(ch.from_numpy(X_train).cuda(), ch.from_numpy(y_train.astype(np.int32)).cuda())\n",
    "train_loader = DataLoader(train_dataset, batch_size=32)\n",
    "val_dataset = TensorDataset(ch.from_numpy(X_val).cuda(), ch.from_numpy(y_val.astype(np.int32)).cuda())\n",
    "val_loader = DataLoader(val_dataset, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6a620e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from functools import partial\n",
    "from torch import optim, nn, utils, Tensor\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "import pytorch_lightning as pl\n",
    "from torchmetrics import AUROC\n",
    "\n",
    "# define any number of nn.Modules (or use your current ones)\n",
    "encoder = nn.Sequential(nn.Linear(28 * 28, 64), nn.ReLU(), nn.Linear(64, 3))\n",
    "decoder = nn.Sequential(nn.Linear(3, 64), nn.ReLU(), nn.Linear(64, 28 * 28))\n",
    "\n",
    "\n",
    "# define the LightningModule\n",
    "class LitModel(pl.LightningModule):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.criterion = ch.nn.BCEWithLogitsLoss()\n",
    "        self.train_auroc = AUROC(task=\"binary\")\n",
    "        self.val_auroc = AUROC(task=\"binary\")\n",
    "\n",
    "    def training_step(self, batch, batch_idx, mode='train'):\n",
    "        x, y = batch\n",
    "        predictions = self.model(x).squeeze().ravel()\n",
    "        y = y.unsqueeze(1).repeat(1, x.shape[1]).ravel()\n",
    "        loss = self.criterion(predictions, y.float()).ravel()\n",
    "        self.train_auroc(ch.sigmoid(predictions.ravel()), y.ravel())\n",
    "        self.log(\"train_auroc\", self.train_auroc, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self,batch, batch_idx, mode='train'):\n",
    "        x, y = batch\n",
    "        predictions = self.model(x).squeeze().ravel()\n",
    "        y = y.unsqueeze(1).repeat(1, x.shape[1]).ravel()\n",
    "        loss = self.criterion(predictions, y.float()).ravel()\n",
    "        self.val_auroc(ch.sigmoid(predictions.ravel()), y.ravel())\n",
    "        self.log(\"val_auroc\", self.val_auroc, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=1e-3, weight_decay=0.0005)\n",
    "        return optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c12dd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = OPSUMTransformer(\n",
    "    input_dim=X_train.shape[2],\n",
    "    num_layers=24,\n",
    "    model_dim=256,\n",
    "    dropout=0.05,\n",
    "    ff_dim=512,\n",
    "    num_heads=8,\n",
    "    num_classes=1,\n",
    "    max_dim=500,\n",
    "    pos_encode_factor=1\n",
    ")\n",
    "module = LitModel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3218195f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(accelerator='gpu', devices=1, max_epochs=50,\n",
    "                     callbacks=[])\n",
    "trainer.fit(model=module, train_dataloaders=train_loader, val_dataloaders=val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8c0f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69624ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.cuda()(ch.from_numpy(X_train).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdd17f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.prod(X_train.shape) * 4 / 2**20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b605b348",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_average(features, labels):\n",
    "    avg_features = np.cumsum(features, 1) / (np.arange(1, features.shape[1] + 1)[None, :, None])\n",
    "    min_features = np.minimum.accumulate(features, 1)\n",
    "    max_features = np.maximum.accumulate(features, 1)\n",
    "    all_features = np.concatenate([features, avg_features, min_features, max_features], 2)\n",
    "    all_features = all_features.reshape(-1, all_features.shape[-1])\n",
    "    labels = labels[:, None].repeat(72, 1).ravel()\n",
    "    print(labels.shape)\n",
    "    return all_features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d557dc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = XGBClassifier(n_estimators=65, learning_rate=0.1, reg_lambda=50, alpha=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12ef59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_features_train, flat_labels_train = prep_average(X_train, y_train)\n",
    "flat_features_val, flat_labels_val = prep_average(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d74472e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time classifier.fit(flat_features_train, flat_labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea505a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_train = classifier.predict_proba(flat_features_train)[:, 1].reshape(-1, 72).T\n",
    "prediction_val = classifier.predict_proba(flat_features_val)[:, 1].reshape(-1, 72).T\n",
    "scores_train = []\n",
    "scores_val = []\n",
    "for time in range(72):\n",
    "    scores_train.append(roc_auc_score(y_train, prediction_train[time]))\n",
    "    scores_val.append(roc_auc_score(y_val, prediction_val[time]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8f9bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(flat_labels_val, prediction_val.T.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7d5421",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(scores_val, label='Val set')\n",
    "plt.gca().set_ylabel('ROC AUC')\n",
    "plt.xlabel('Hours from admission')\n",
    "plt.axhline(roc_auc_score(flat_labels_val, prediction_val.T.ravel()), label='average over time')\n",
    "plt.plot(scores_train, label='Test set')\n",
    "plt.grid()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae94a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fa59d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f40ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, c  = roc_curve(flat_labels_val, prediction_val.T.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5327b3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(a, b)\n",
    "plt.plot(1 - b, 1 - a)\n",
    "plt.grid()\n",
    "plt.gca().set_aspect('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4686f799",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1763970",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = MLPClassifier((128, 128, 64), learning_rate='adaptive', alpha=12.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6394e96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time model2.fit(flat_features_train, flat_labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d1bab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_train = model2.predict_proba(flat_features_train)[:, 1].reshape(-1, 72).T\n",
    "prediction_val = model2.predict_proba(flat_features_val)[:, 1].reshape(-1, 72).T\n",
    "scores_train = []\n",
    "scores_val = []\n",
    "for time in range(72):\n",
    "    scores_train.append(roc_auc_score(y_train, prediction_train[time]))\n",
    "    scores_val.append(roc_auc_score(y_val, prediction_val[time]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4549e575",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(flat_labels_val, prediction_val.T.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a4e179",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(scores_val, label='Val set')\n",
    "plt.gca().set_ylabel('ROC AUC')\n",
    "plt.xlabel('Hours from admission')\n",
    "plt.axhline(roc_auc_score(flat_labels_val, prediction_val.T.ravel()), label='average over time')\n",
    "plt.plot(scores_train, label='Train set')\n",
    "plt.grid()\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

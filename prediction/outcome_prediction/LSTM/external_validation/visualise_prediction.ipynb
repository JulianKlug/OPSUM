{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Interactive visualisation of the prediction for a single subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randint\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from prediction.mrs_outcome_prediction.LSTM.testing.shap_helper_functions import check_shap_version_compatibility\n",
    "from prediction.mrs_outcome_prediction.data_loading.data_formatting import format_to_2d_table_with_time, \\\n",
    "    feature_order_verification\n",
    "from prediction.utils.utils import check_data\n",
    "from preprocessing.preprocessing_tools.normalisation.reverse_normalisation import reverse_normalisation\n",
    "from prediction.mrs_outcome_prediction.LSTM.testing.visualisation_helper_functions import reverse_normalisation_for_subj\n",
    "from sklearn.model_selection import train_test_split\n",
    "from prediction.mrs_outcome_prediction.data_loading.data_formatting import features_to_numpy, \\\n",
    "    link_patient_id_to_outcome, numpy_to_lookup_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shap values require very specific versions\n",
    "check_shap_version_compatibility()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Pre-computation\n",
    "\n",
    "*This takes some time to compute and should be run in advance*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_weights_path = '/Users/jk1/temp/mimic/prediction/3M_Death/test_LSTM_sigmoid_all_balanced_0.6_1_True_RMSprop_3M Death_8_3/sigmoid_all_balanced_0.6_1_True_RMSprop_3M Death_8_3.hdf5'\n",
    "\n",
    "training_features_path = '/Users/jk1/temp/opsum_prepro_output/preprocessed_features_27092022_172403.csv'\n",
    "training_labels_path = '/Users/jk1/temp/opsum_prepro_output/preprocessed_outcomes_27092022_172403.csv'\n",
    "\n",
    "validation_features_path = '/Users/jk1/temp/mimic/preprocessing/mimic_prepro_30122022_133144/preprocessed_features_30122022_133144.csv'\n",
    "validation_labels_path = '/Users/jk1/temp/mimic/preprocessing/mimic_prepro_30122022_133144/preprocessed_outcomes_30122022_133144.csv'\n",
    "\n",
    "normalisation_parameters_path = '/Users/jk1/temp/mimic/preprocessing/mimic_prepro_30122022_133144/logs_30122022_133144/reference_population_normalisation_parameters.csv'\n",
    "shap_over_time_path = '/Users/jk1/temp/mimic/prediction/3M_Death/test_LSTM_sigmoid_all_balanced_0.6_1_True_RMSprop_3M Death_8_3/deep_explainer_shap_values_over_ts.pkl'\n",
    "predictions_over_time_path = '/Users/jk1/temp/mimic/prediction/3M_Death/test_LSTM_sigmoid_all_balanced_0.6_1_True_RMSprop_3M Death_8_3/predictions_over_timesteps.pkl'\n",
    "out_dir = '/Users/jk1/Downloads'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_figures = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome = '3M Death'\n",
    "\n",
    "model_name = os.path.basename(model_weights_path).split('.hdf5')[0]\n",
    "\n",
    "model_config = {\n",
    "    'activation': model_name.split('_')[0],\n",
    "    'batch': model_name.split('_')[1],\n",
    "    'data': model_name.split('_')[2],\n",
    "    'dropout': float(model_name.split('_')[3]),\n",
    "    'layers': int(model_name.split('_')[4]),\n",
    "    'masking': model_name.split('_')[5],\n",
    "    'optimizer': model_name.split('_')[6],\n",
    "    'units': int(model_name.split('_')[8]),\n",
    "    'cv_fold': int(model_name.split('_')[9]),\n",
    "    'seed': 42,\n",
    "    'test_size': 0.20\n",
    "}\n",
    "\n",
    "override_masking_value = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(shap_over_time_path, 'rb') as handle:\n",
    "    shap_values_over_time = pickle.load(handle)\n",
    "\n",
    "normalisation_parameters_df = pd.read_csv(normalisation_parameters_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(predictions_over_time_path, 'rb') as handle:\n",
    "    predictions_over_time = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Load the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LOAD THE TRAINING DATASET\n",
    "derivation_X, derivation_y = format_to_2d_table_with_time(feature_df_path=training_features_path, outcome_df_path=training_labels_path,\n",
    "                                    outcome=outcome)\n",
    "\n",
    "check_data(derivation_X)\n",
    "\n",
    "# Reduce every patient to a single outcome (to avoid duplicates)\n",
    "all_pids_with_outcome = link_patient_id_to_outcome(derivation_y, outcome)\n",
    "pid_train, pid_test, _, _ = train_test_split(all_pids_with_outcome.patient_id.tolist(),\n",
    "                                                all_pids_with_outcome.outcome.tolist(),\n",
    "                                                stratify=all_pids_with_outcome.outcome.tolist(),\n",
    "                                                test_size=model_config['test_size'],\n",
    "                                                random_state=model_config['seed'])\n",
    "train_X_df = derivation_X[derivation_X.patient_id.isin(pid_train)]\n",
    "train_X_np = features_to_numpy(train_X_df,\n",
    "                               ['case_admission_id', 'relative_sample_date_hourly_cat', 'sample_label', 'value'])\n",
    "feature_order_verification(train_X_np)\n",
    "# Remove the case_admission_id, sample_label, and time_step_label columns from the data\n",
    "train_X_np = train_X_np[:, :, :, -1].astype('float32')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Load validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "X, y = format_to_2d_table_with_time(feature_df_path=validation_features_path, outcome_df_path=validation_labels_path,\n",
    "                                    outcome=outcome)\n",
    "\n",
    "n_time_steps = X.relative_sample_date_hourly_cat.max() + 1\n",
    "n_channels = X.sample_label.unique().shape[0]\n",
    "# test if data is corrupted\n",
    "check_data(X)\n",
    "test_X_np = features_to_numpy(X,\n",
    "                              ['case_admission_id', 'relative_sample_date_hourly_cat', 'sample_label', 'value'])\n",
    "# ensure that the order of features (3rd dimension) is the one predefined for the model\n",
    "feature_order_verification(test_X_np)\n",
    "# create look-up table for case_admission_ids, sample_labels and relative_sample_date_hourly_cat\n",
    "test_features_lookup_table = numpy_to_lookup_table(test_X_np)\n",
    "test_y_np = np.array([y[y.case_admission_id == cid].outcome.values[0] for cid in\n",
    "                      test_X_np[:, 0, 0, 0]]).astype('float32')\n",
    "# Remove the case_admission_id, sample_label, and time_step_label columns from the data\n",
    "test_X_np = test_X_np[:, :, :, -1].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(test_features_lookup_table['sample_label'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_normalised_train_X_df = reverse_normalisation(train_X_df, normalisation_parameters_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Choose subject and load or compute prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj = randint(0, len(test_X_np))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Subject index: {subj}')\n",
    "print(f'Overall {outcome} prediction: {predictions_over_time[-1, subj] * 100:.2f}%')\n",
    "print(f'Final outcome: {outcome} - {bool(test_y_np[subj])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_pred_over_ts = predictions_over_time[:,subj]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Plot overall subject prediction & explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a bar plot showing impact of most important features on the prediction across all n_time_steps\n",
    "# find index of 3 features with biggest positive shap impart\n",
    "selected_positive_features = np.squeeze(shap_values_over_time[-1])[subj].sum(axis=0).argsort()[-n_features:][::-1]\n",
    "\n",
    "# find index of 3 features with biggest negative shap impart\n",
    "selected_negative_features = np.squeeze(shap_values_over_time[-1])[subj].sum(axis=0).argsort()[:n_features][::-1]\n",
    "\n",
    "selected_features = np.concatenate((selected_positive_features, selected_negative_features))\n",
    "\n",
    "fig1 = plt.figure(figsize=(15,5))\n",
    "ax1 = fig1.add_subplot(121)\n",
    "ax = sns.barplot(y=np.array(features)[selected_features], x=np.squeeze(shap_values_over_time[-1])[subj].sum(axis=0)[selected_features], palette=\"RdBu_r\")\n",
    "ax.title.set_text(f'SHAP values for subj {subj} ')\n",
    "\n",
    "non_norm_subj_df = reverse_normalisation_for_subj(pd.DataFrame(data=test_X_np[subj], columns = features), normalisation_parameters_df)\n",
    "median_norm_feature_df = non_norm_subj_df.median(axis=0)[selected_features]\n",
    "\n",
    "ax2 = fig1.add_subplot(122)\n",
    "font_size=12\n",
    "bbox=[0, 0, 1, 1]\n",
    "ax2.axis('off')\n",
    "cell_text = []\n",
    "for row in range(len(median_norm_feature_df)):\n",
    "    cell_text.append([median_norm_feature_df.iloc[row].astype(str)])\n",
    "mpl_table = ax2.table(cellText = cell_text, rowLabels = median_norm_feature_df.index, bbox=bbox, colLabels=['Normalised value'], cellLoc='center', colLoc='center', loc='center')\n",
    "mpl_table.auto_set_font_size(False)\n",
    "mpl_table.set_fontsize(font_size)\n",
    "fig1.set_tight_layout(True)\n",
    "# set figure title\n",
    "fig1.suptitle(f'Explanation of prediction for subj {subj} with a probability of {outcome} of {subj_pred_over_ts[-1]*100:.2f}%', fontsize=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_figures:\n",
    "    fig1.savefig(os.path.join(out_dir, 'final_prediction.png'), dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Plot relevant features in relation to training population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2 = plt.figure(figsize=(15, 12))\n",
    "plt.subplots_adjust(hspace=0.2)\n",
    "plt.suptitle(\"Selected features\", fontsize=18, y=0.99, x=0.52, horizontalalignment='center')\n",
    "\n",
    "# set number of columns (use 3 to demonstrate the change)\n",
    "ncols = 3\n",
    "# calculate number of rows\n",
    "nrows = len(selected_features) // ncols + (len(selected_features) % ncols > 0)\n",
    "\n",
    "# loop through the length of features and keep track of index\n",
    "for n, feature in enumerate(selected_features):\n",
    "    # add a new subplot iteratively using nrows and cols\n",
    "    ax = plt.subplot(nrows, ncols, n + 1)\n",
    "\n",
    "    temp_pop_df = non_normalised_train_X_df[non_normalised_train_X_df.sample_label == features[feature]]\n",
    "    sns.histplot(temp_pop_df.value, ax=ax)\n",
    "    plt.scatter(median_norm_feature_df[features[feature]], 0, marker='o', s=500)\n",
    "    if (n % ncols) == 1:\n",
    "        if n <= len(selected_features) / 2:\n",
    "            ax.set_title(r\"$\\bf{Positive\\ features}$\" +f'\\n\\n{features[feature]}')\n",
    "        else:\n",
    "            ax.set_title(r\"$\\bf{Negative\\ features}$\" + f'\\n\\n{features[feature]}')\n",
    "\n",
    "    else:\n",
    "        ax.set_title(features[feature])\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_figures:\n",
    "    fig2.savefig(os.path.join(out_dir, 'features_histogram_comparison.png'), dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Plot evolution of prediction & explanation over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_prevailing_features = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_shap_values_over_time = np.array([shap_values_over_time[ts][0].sum(axis=1) for ts in range(n_time_steps)])\n",
    "\n",
    "# find index of 3 features with biggest positive shap impart & index of 3 features with biggest negative shap impart\n",
    "if overall_prevailing_features:\n",
    "    # prevailing features over cumulative time\n",
    "    selected_negative_features = cumulative_shap_values_over_time[:, subj].sum(axis=0).argsort()[:n_features][::-1]\n",
    "    selected_positive_features = cumulative_shap_values_over_time[:, subj].sum(axis=0).argsort()[-n_features:][::-1]\n",
    "else:\n",
    "    # prevailing features at last timepoint\n",
    "    selected_positive_features = np.squeeze(shap_values_over_time[-1])[subj].sum(axis=0).argsort()[-n_features:][::-1]\n",
    "    selected_negative_features = np.squeeze(shap_values_over_time[-1])[subj].sum(axis=0).argsort()[:n_features][::-1]\n",
    "\n",
    "selected_features = np.concatenate((selected_positive_features, selected_negative_features))\n",
    "\n",
    "fig3 = plt.figure(figsize=(15,10))\n",
    "\n",
    "k=1\n",
    "alpha=0.3\n",
    "\n",
    "timestep_axis = np.array(range(n_time_steps))\n",
    "\n",
    "positive_color_palette = sns.color_palette(\"mako\", n_colors=len(selected_positive_features))\n",
    "negative_color_palette = sns.color_palette(\"flare_r\", n_colors=len(selected_negative_features))\n",
    "\n",
    "timestep_axis = np.array(range(n_time_steps))\n",
    "ax = sns.lineplot(x=timestep_axis, y=subj_pred_over_ts, label='probability', linewidth = 2)\n",
    "\n",
    "\n",
    "pos_baseline = subj_pred_over_ts\n",
    "neg_baseline = subj_pred_over_ts\n",
    "pos_count = 0\n",
    "neg_count = 0\n",
    "for i, feature in enumerate(selected_features):\n",
    "    subj_cumulative_shap_value_over_time = cumulative_shap_values_over_time[:, subj, feature]\n",
    "    positive_portion = (subj_cumulative_shap_value_over_time > 0)\n",
    "    negative_portion = (subj_cumulative_shap_value_over_time < 0)\n",
    "\n",
    "    pos_function = subj_cumulative_shap_value_over_time.copy()\n",
    "    pos_function[negative_portion] = 0\n",
    "\n",
    "    neg_function = subj_cumulative_shap_value_over_time.copy()\n",
    "    neg_function[positive_portion] = 0\n",
    "\n",
    "    if feature in selected_positive_features:\n",
    "        feature_color = positive_color_palette[pos_count]\n",
    "        pos_count += 1\n",
    "    else:\n",
    "        feature_color = negative_color_palette[neg_count]\n",
    "        neg_count += 1\n",
    "\n",
    "    positive_feature = pos_baseline + k * pos_function\n",
    "    ax.fill_between(timestep_axis, pos_baseline, positive_feature, color=feature_color, alpha=alpha, label=features[feature])\n",
    "    pos_baseline = positive_feature\n",
    "\n",
    "    negative_feature = neg_baseline + k * neg_function\n",
    "    ax.fill_between(timestep_axis, negative_feature, neg_baseline, color=feature_color, alpha=alpha)\n",
    "    neg_baseline = negative_feature\n",
    "\n",
    "ax.legend(fontsize='x-large')\n",
    "\n",
    "ax.set_title(f'Predictions for subject {subj} of external validation set along time', fontsize=20)\n",
    "ax.set_xlabel('Time from admission (hours)', fontsize=15)\n",
    "ax.set_ylabel(f'Probability of {outcome}', fontsize=15)\n",
    "\n",
    "plt.plot()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_figures:\n",
    "    fig3.savefig(os.path.join(out_dir, 'prediction_over_time.png'), dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Plot selected features over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig4 = plt.figure(figsize=(15, 12))\n",
    "plt.subplots_adjust(hspace=0.2)\n",
    "plt.suptitle(\"Selected features\", fontsize=18, y=0.99, x=0.52, horizontalalignment='center')\n",
    "\n",
    "# set number of columns (use 3 to demonstrate the change)\n",
    "ncols = 3\n",
    "# calculate number of rows\n",
    "nrows = len(selected_features) // ncols + (len(selected_features) % ncols > 0)\n",
    "\n",
    "pos_count = 0\n",
    "neg_count = 0\n",
    "# loop through the length of features and keep track of index\n",
    "for n, feature in enumerate(selected_features):\n",
    "    # add a new subplot iteratively using nrows and cols\n",
    "    ax = plt.subplot(nrows, ncols, n + 1)\n",
    "\n",
    "    if feature in selected_positive_features:\n",
    "        feature_color = positive_color_palette[pos_count]\n",
    "        pos_count += 1\n",
    "    else:\n",
    "        feature_color = negative_color_palette[neg_count]\n",
    "        neg_count += 1\n",
    "    sns.lineplot(y=features[feature], x='index', data=non_norm_subj_df.reset_index(), color=feature_color, ax=ax)\n",
    "\n",
    "    if (n % ncols) == 1:\n",
    "        if n <= len(selected_features) / 2:\n",
    "            ax.set_title(r\"$\\bf{Positive\\ features}$\" +f'\\n\\n{features[feature]}')\n",
    "        else:\n",
    "            ax.set_title(r\"$\\bf{Negative\\ features}$\" + f'\\n\\n{features[feature]}')\n",
    "    else:\n",
    "        ax.set_title(features[feature])\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_figures:\n",
    "    fig4.savefig(os.path.join(out_dir, 'features_over_time.png'), dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Plot contribution of a specific feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = [\"median_mean_blood_pressure\", \"median_diastolic_blood_pressure\", \"median_systolic_blood_pressure\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features_idx = [np.where(np.array(features) == selected_feature)[0][0] for selected_feature in selected_features]\n",
    "selected_features_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_shap_values_over_time = np.array([shap_values_over_time[ts][0].sum(axis=1) for ts in range(n_time_steps)])\n",
    "subj_pred_over_ts = predictions_over_time[:,subj]\n",
    "\n",
    "fig3 = plt.figure(figsize=(15,10))\n",
    "\n",
    "k=1\n",
    "alpha=0.3\n",
    "\n",
    "timestep_axis = np.array(range(n_time_steps))\n",
    "\n",
    "positive_color_palette = sns.color_palette(\"mako\", n_colors=len(selected_positive_features))\n",
    "negative_color_palette = sns.color_palette(\"flare_r\", n_colors=len(selected_negative_features))\n",
    "\n",
    "timestep_axis = np.array(range(n_time_steps))\n",
    "ax = sns.lineplot(x=timestep_axis, y=subj_pred_over_ts, label='probability', linewidth = 2)\n",
    "ax2 = ax.twinx()\n",
    "\n",
    "\n",
    "pos_baseline = subj_pred_over_ts\n",
    "neg_baseline = subj_pred_over_ts\n",
    "pos_count, neg_count = 0, 0\n",
    "for i, feature in enumerate(selected_features_idx):\n",
    "    subj_cumulative_shap_value_over_time = cumulative_shap_values_over_time[:, subj, feature]\n",
    "    positive_portion = (subj_cumulative_shap_value_over_time > 0)\n",
    "    negative_portion = (subj_cumulative_shap_value_over_time < 0)\n",
    "\n",
    "    pos_function = subj_cumulative_shap_value_over_time.copy()\n",
    "    pos_function[negative_portion] = 0\n",
    "\n",
    "    neg_function = subj_cumulative_shap_value_over_time.copy()\n",
    "    neg_function[positive_portion] = 0\n",
    "\n",
    "    if sum(subj_cumulative_shap_value_over_time) > 0:\n",
    "        feature_color = positive_color_palette[pos_count]\n",
    "        pos_count += 1\n",
    "    else:\n",
    "        feature_color = negative_color_palette[neg_count]\n",
    "        neg_count += 1\n",
    "\n",
    "    positive_feature = pos_baseline + k * pos_function\n",
    "    ax.fill_between(timestep_axis, pos_baseline, positive_feature, color=feature_color, alpha=alpha, label=features[feature])\n",
    "    pos_baseline = positive_feature\n",
    "\n",
    "    negative_feature = neg_baseline + k * neg_function\n",
    "    ax.fill_between(timestep_axis, negative_feature, neg_baseline, color=feature_color, alpha=alpha)\n",
    "    neg_baseline = negative_feature\n",
    "\n",
    "    sns.scatterplot(y=features[feature], x='index', data=non_norm_subj_df.reset_index(), ax=ax2, legend=False, color=feature_color)\n",
    "\n",
    "ax.legend(fontsize='x-large')\n",
    "\n",
    "ax.set_title(f'Predictions for subject {subj} of test set along time', fontsize=20)\n",
    "ax.set_xlabel('Time from admission (hours)', fontsize=15)\n",
    "ax.set_ylabel(f'Probability of {outcome}', fontsize=15)\n",
    "\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig4 = plt.figure(figsize=(15, 12))\n",
    "plt.subplots_adjust(hspace=0.2)\n",
    "plt.suptitle(\"Selected features\", fontsize=18, y=0.99, x=0.52, horizontalalignment='center')\n",
    "\n",
    "# set number of columns (use 3 to demonstrate the change)\n",
    "ncols = 3\n",
    "# calculate number of rows\n",
    "nrows = len(selected_features_idx) // ncols + (len(selected_features_idx) % ncols > 0)\n",
    "\n",
    "pos_count = 0\n",
    "neg_count = 0\n",
    "# loop through the length of features and keep track of index\n",
    "for n, feature in enumerate(selected_features_idx):\n",
    "    # add a new subplot iteratively using nrows and cols\n",
    "    ax = plt.subplot(nrows, ncols, n + 1)\n",
    "\n",
    "    if sum(subj_cumulative_shap_value_over_time) > 0:\n",
    "        feature_color = positive_color_palette[pos_count]\n",
    "        pos_count += 1\n",
    "    else:\n",
    "        feature_color = negative_color_palette[neg_count]\n",
    "        neg_count += 1\n",
    "    sns.lineplot(y=features[feature], x='index', data=non_norm_subj_df.reset_index(), color=feature_color, ax=ax)\n",
    "\n",
    "    ax.set_title(features[feature])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values_over_time[-1][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "auto=False\n",
    "\n",
    "X_test_2D = test_X_np.reshape(-1,n_channels)\n",
    "shap_values_2D = shap_values_over_time[-1][0].reshape(-1,n_channels)\n",
    "x_test_2d = pd.DataFrame(data=X_test_2D, columns = features)\n",
    "\n",
    "for n, feature in enumerate(selected_features_idx):\n",
    "    if auto == True:\n",
    "        # automatic choice of interaction\n",
    "        shap.dependence_plot(features[feature], shap_values_2D, x_test_2d)\n",
    "    else:\n",
    "        shap.dependence_plot(features[feature], shap_values_2D, x_test_2d, interaction_index=\"median_NIHSS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Finding interesting subjects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Big change in prediction:\n",
    "- subj 58\n",
    "- subj 95\n",
    "\n",
    "Standard:\n",
    "- subj 87"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Visualize change in prediction from start to end of the 72h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_over_time[-1,:] - predictions_over_time[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

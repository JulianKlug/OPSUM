{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_over_time_path = '/Users/jk1/temp/opsum_prediction_output/LSTM_72h_testing/3M_mRS02/2023_01_02_1057/test_LSTM_sigmoid_all_balanced_0.2_2_True_RMSprop_3M mRS 0-2_16_3/predictions_over_timesteps.pkl'\n",
    "features_path = '/Users/jk1/temp/opsum_prepro_output/gsu_prepro_01012023_233050/preprocessed_features_01012023_233050.csv'\n",
    "labels_path = '/Users/jk1/temp/opsum_prepro_output/gsu_prepro_01012023_233050/preprocessed_outcomes_01012023_233050.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome =  \"3M mRS 0-2\"\n",
    "test_size = 0.2\n",
    "seed = 42\n",
    "n_time_steps = 72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(predictions_over_time_path, 'rb') as handle:\n",
    "    predictions_over_time = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from prediction.outcome_prediction.data_loading.data_formatting import format_to_2d_table_with_time, \\\n",
    "    link_patient_id_to_outcome, features_to_numpy\n",
    "\n",
    "# load the dataset\n",
    "X, y = format_to_2d_table_with_time(feature_df_path=features_path, outcome_df_path=labels_path,\n",
    "                                    outcome=outcome)\n",
    "\n",
    "# Reduce every patient to a single outcome (to avoid duplicates)\n",
    "all_pids_with_outcome = link_patient_id_to_outcome(y, outcome)\n",
    "pid_train, pid_test, y_pid_train, y_pid_test = train_test_split(all_pids_with_outcome.patient_id.tolist(),\n",
    "                                                                all_pids_with_outcome.outcome.tolist(),\n",
    "                                                                stratify=all_pids_with_outcome.outcome.tolist(),\n",
    "                                                                test_size=test_size,\n",
    "                                                                random_state=seed)\n",
    "\n",
    "test_X_df = X[X.patient_id.isin(pid_test)]\n",
    "test_y_df = y[y.patient_id.isin(pid_test)]\n",
    "\n",
    "test_X_np = features_to_numpy(test_X_df,\n",
    "                              ['case_admission_id', 'relative_sample_date_hourly_cat', 'sample_label', 'value'])\n",
    "test_y_np = np.array([test_y_df[test_y_df.case_admission_id == cid].outcome.values[0] for cid in\n",
    "                      test_X_np[:, 0, 0, 0]]).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc_scores = []\n",
    "for ts in range(n_time_steps):\n",
    "    modified_time_steps = ts + 1\n",
    "    y_pred = predictions_over_time[ts]\n",
    "    roc_auc_scores.append([modified_time_steps, roc_auc_score(test_y_np, y_pred)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(roc_auc_scores, columns=['n_hours', 'roc_auc_score'])\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "ax = sns.lineplot(x='n_hours', y='roc_auc_score', data=results_df, legend=True)\n",
    "ax.set_title('Model performance in the holdout test dataset as a function of observation period')\n",
    "ax.set_xlabel('Time after admission (hours)')\n",
    "ax.set_ylabel('ROC AUC')\n",
    "ax.set_ybound(0.8,0.9)\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig(os.path.join('/Users/jk1/Downloads', f'{outcome}_roc_auc_scores_over_time.png'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Performance at 24h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "roc_auc_scores_bs = []\n",
    "ts = 24\n",
    "\n",
    "n_iterations = 1000\n",
    "for i in range(n_iterations):\n",
    "    y_pred_bs, y_bs = resample(predictions_over_time[ts], test_y_np, replace=True)\n",
    "\n",
    "    # evaluate model\n",
    "    roc_auc_bs = roc_auc_score(y_bs, y_pred_bs)\n",
    "    roc_auc_scores_bs.append(roc_auc_bs)\n",
    "\n",
    "median_roc_auc = np.percentile(roc_auc_scores_bs, 50)\n",
    "# get 95% interval\n",
    "alpha = 100 - 95\n",
    "lower_ci_roc_auc = np.percentile(roc_auc_scores_bs, alpha / 2)\n",
    "upper_ci_roc_auc = np.percentile(roc_auc_scores_bs, 100 - alpha / 2)\n",
    "\n",
    "print(median_roc_auc, lower_ci_roc_auc, upper_ci_roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

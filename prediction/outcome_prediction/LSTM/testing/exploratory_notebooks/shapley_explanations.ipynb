{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## SHAP additive explanation models\n",
    "\n",
    "Requirements:\n",
    "- TensorFlow 1.14\n",
    "- Python 3.7\n",
    "- Protobuf downgrade to 3.20: `pip install protobuf==3.20`\n",
    "- downgrade h5py to 2.10: `pip install h5py==2.10`\n",
    "- turn off masking in LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from prediction.outcome_prediction.LSTM.testing.shap_helper_functions import check_shap_version_compatibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shap values require very specific versions\n",
    "check_shap_version_compatibility()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the JS visualization code to the notebook\n",
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_weights_path = '/Users/jk1/temp/opsum_prediction_output/LSTM_72h_testing/3M_mRS02/2023_01_02_1057/test_LSTM_sigmoid_all_balanced_0.2_2_True_RMSprop_3M mRS 0-2_16_3/sigmoid_all_balanced_0.2_2_True_RMSprop_3M mRS 0-2_16_3.hdf5'\n",
    "features_path = '/Users/jk1/temp/opsum_prepro_output/gsu_prepro_01012023_233050/preprocessed_features_01012023_233050.csv'\n",
    "labels_path = '/Users/jk1/temp/opsum_prepro_output/gsu_prepro_01012023_233050/preprocessed_outcomes_01012023_233050.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome = '3M mRS 0-2'\n",
    "masking = True\n",
    "units = 16\n",
    "activation = 'sigmoid'\n",
    "dropout = 0.2\n",
    "layers = 2\n",
    "optimizer = 'RMSprop'\n",
    "seed = 42\n",
    "test_size = 0.20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "masking as to be overridden to False for shapley values to be computed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "override_masking_value = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prediction.outcome_prediction.data_loading.data_formatting import format_to_2d_table_with_time\n",
    "\n",
    "# load the dataset\n",
    "X, y = format_to_2d_table_with_time(feature_df_path=features_path, outcome_df_path=labels_path,\n",
    "                                    outcome=outcome)\n",
    "\n",
    "n_time_steps = X.relative_sample_date_hourly_cat.max() + 1\n",
    "n_channels = X.sample_label.unique().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from prediction.outcome_prediction.data_loading.data_formatting import features_to_numpy, \\\n",
    "    link_patient_id_to_outcome, numpy_to_lookup_table\n",
    "\n",
    "# Reduce every patient to a single outcome (to avoid duplicates)\n",
    "all_pids_with_outcome = link_patient_id_to_outcome(y, outcome)\n",
    "pid_train, pid_test, y_pid_train, y_pid_test = train_test_split(all_pids_with_outcome.patient_id.tolist(),\n",
    "                                                                all_pids_with_outcome.outcome.tolist(),\n",
    "                                                                stratify=all_pids_with_outcome.outcome.tolist(),\n",
    "                                                                test_size=test_size,\n",
    "                                                                random_state=seed)\n",
    "\n",
    "test_X_df = X[X.patient_id.isin(pid_test)]\n",
    "test_y_df = y[y.patient_id.isin(pid_test)]\n",
    "train_X_df = X[X.patient_id.isin(pid_train)]\n",
    "train_y_df = y[y.patient_id.isin(pid_train)]\n",
    "\n",
    "train_X_np = features_to_numpy(train_X_df,\n",
    "                                 ['case_admission_id', 'relative_sample_date_hourly_cat', 'sample_label', 'value'])\n",
    "test_X_np = features_to_numpy(test_X_df,\n",
    "                              ['case_admission_id', 'relative_sample_date_hourly_cat', 'sample_label', 'value'])\n",
    "train_y_np = np.array([train_y_df[train_y_df.case_admission_id == cid].outcome.values[0] for cid in\n",
    "                         train_X_np[:, 0, 0, 0]]).astype('float32')\n",
    "test_y_np = np.array([test_y_df[test_y_df.case_admission_id == cid].outcome.values[0] for cid in\n",
    "                      test_X_np[:, 0, 0, 0]]).astype('float32')\n",
    "\n",
    "\n",
    "# create look-up table for case_admission_ids, sample_labels and relative_sample_date_hourly_cat\n",
    "test_features_lookup_table = numpy_to_lookup_table(test_X_np)\n",
    "train_features_lookup_table = numpy_to_lookup_table(train_X_np)\n",
    "\n",
    "# Remove the case_admission_id, sample_label, and time_step_label columns from the data\n",
    "test_X_np = test_X_np[:, :, :, -1].astype('float32')\n",
    "train_X_np = train_X_np[:, :, :, -1].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prediction.utils.scoring import precision, recall, matthews\n",
    "from prediction.outcome_prediction.LSTM.LSTM import lstm_generator\n",
    "\n",
    "model = lstm_generator(x_time_shape=n_time_steps, x_channels_shape=n_channels, masking=override_masking_value, n_units=units,\n",
    "                           activation=activation, dropout=dropout, n_layers=layers)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer,\n",
    "              metrics=['accuracy', precision, recall, matthews])\n",
    "\n",
    "model.load_weights(model_weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert tf.__version__ == '1.14.0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## DeepSHAP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X_np.shape, test_X_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the training data for deep explainer => can use fewer instances\n",
    "explainer = shap.DeepExplainer(model, train_X_np)\n",
    "# explain the testing instances (can use fewer instances)\n",
    "# explaining each prediction requires 2 * background dataset size runs\n",
    "shap_values = explainer.shap_values(test_X_np)\n",
    "# init the JS visualization code\n",
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer.expected_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(test_features_lookup_table['sample_label'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(features)\n",
    "print(len(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts=0\n",
    "subj=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values[0][subj][ts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X_np[subj][ts].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts=56\n",
    "subj=11\n",
    "x_test_df = pd.DataFrame(data=test_X_np[subj][ts].reshape(1,n_channels), columns = features)\n",
    "shap.force_plot(explainer.expected_value[0], shap_values[0][subj][ts], x_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average over all n_time_steps\n",
    "x_test_df = pd.DataFrame(data=test_X_np[subj].mean(axis=0).reshape(1,n_channels), columns = features)\n",
    "shap.force_plot(explainer.expected_value[0], shap_values[0][subj].mean(axis=0), x_test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Local accuracy: Check sum of shap values vs prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values[0][subj].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verifying local accuracy of explainer model\n",
    "subj = 11\n",
    "pred_i = model.predict(test_X_np[subj:subj+1])\n",
    "sum_shap_i = shap_values[0][subj].sum() + explainer.expected_value[0]\n",
    "\n",
    "pred_i, sum_shap_i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "As expected, these are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "\n",
    "# Plot SHAP for ONLY one subj i\n",
    "subj = randint(0, len(test_X_np))\n",
    "print(subj, model.predict(test_X_np[subj:subj+1]))\n",
    "\n",
    "x_test_df = pd.DataFrame(data=test_X_np[subj], columns = features)\n",
    "shap.force_plot(explainer.expected_value[0], shap_values[0][subj], x_test_df)\n",
    "## Problem:  Can not take into account many observations at the same time.\n",
    "### The pic below explain for only 1 subj for 72 time steps, each time step has 85 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# find index of 3 features with biggest positive shap values\n",
    "selected_positive_features = shap_values[0][subj].mean(axis=0).argsort()[-3:][::-1]\n",
    "\n",
    "# find index of 3 features with biggest negative shap values\n",
    "selected_negative_features = shap_values[0][subj].mean(axis=0).argsort()[:3][::-1]\n",
    "\n",
    "selected_features = np.concatenate((selected_positive_features, selected_negative_features))\n",
    "\n",
    "# normalize shape values by dividing by average shap value for each time step\n",
    "normalized_shap_values = shap_values[0][subj] / shap_values[0][subj].mean(axis=0)\n",
    "\n",
    "fig, [ax1, ax2] = plt.subplots(1, 2, figsize=(10, 5))\n",
    "for feature in selected_features:\n",
    "    sns.scatterplot(y=shap_values[0][subj][:, feature], x=range(n_time_steps), ax=ax1, label=features[feature])\n",
    "    sns.scatterplot(y=normalized_shap_values[:, feature], x=range(n_time_steps), ax=ax2, label=features[feature])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a bar plot showing impact of most important features on the prediction across all n_time_steps\n",
    "subj = randint(0, len(test_X_np))\n",
    "\n",
    "# find index of 3 features with biggest positive shap impart\n",
    "selected_positive_features = shap_values[0][subj].sum(axis=0).argsort()[-3:][::-1]\n",
    "np.array(features)[selected_positive_features]\n",
    "\n",
    "# find index of 3 features with biggest negative shap impart\n",
    "selected_negative_features = shap_values[0][subj].sum(axis=0).argsort()[:3][::-1]\n",
    "np.array(features)[selected_negative_features]\n",
    "\n",
    "selected_features = np.concatenate((selected_positive_features, selected_negative_features))\n",
    "\n",
    "fig = plt.figure(figsize=(15,5))\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax = sns.barplot(y=np.array(features)[selected_features], x=shap_values[0][subj].sum(axis=0)[selected_features], palette=\"RdBu_r\")\n",
    "ax.title.set_text(f'SHAP values for subj {subj} ')\n",
    "\n",
    "x_subj_df = pd.DataFrame(data=test_X_np[subj], columns = features)\n",
    "median_norm_feature_df = x_subj_df.median(axis=0)[selected_features]\n",
    "\n",
    "ax2 = fig.add_subplot(122)\n",
    "font_size=12\n",
    "bbox=[0, 0, 1, 1]\n",
    "ax2.axis('off')\n",
    "cell_text = []\n",
    "for row in range(len(median_norm_feature_df)):\n",
    "    cell_text.append([median_norm_feature_df.iloc[row].astype(str)])\n",
    "mpl_table = ax2.table(cellText = cell_text, rowLabels = median_norm_feature_df.index, bbox=bbox, colLabels=['Normalised value'], cellLoc='center', colLoc='center', loc='center')\n",
    "mpl_table.auto_set_font_size(False)\n",
    "mpl_table.set_fontsize(font_size)\n",
    "fig.set_tight_layout(True)\n",
    "# set figure title\n",
    "fig.suptitle(f'Explanation of prediction for subj {subj} with a probability of good outcome of {model.predict(test_X_np[subj:subj+1])[0][0]:.2f}', fontsize=20)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################# Plot AVERAGE shap values for ALL subjects  #####################\n",
    "## Consider ABSOLUTE of SHAP values ##\n",
    "shap_average_value = np.abs(shap_values[0]).mean(axis=0)\n",
    "\n",
    "x_average_value = pd.DataFrame(data=test_X_np.mean(axis=0), columns = features)\n",
    "shap.force_plot(0, shap_average_value, x_average_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################# Plot AVERAGE shap values for ALL subjects  #####################\n",
    "## Consider average (+ is different from -)\n",
    "shap_average_value = shap_values[0].mean(axis=0)\n",
    "\n",
    "x_average_value = pd.DataFrame(data=test_X_np.mean(axis=0), columns = features)\n",
    "shap.force_plot(explainer.expected_value[0], shap_average_value, x_average_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Feature importance\n",
    "Find most important features by mean absolute SHAP value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ten_most_important_features_by_mean_abs_shap = np.abs(shap_values[0]).mean(axis=(0, 1)).argsort()[::-1][0:13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(features)[ten_most_important_features_by_mean_abs_shap]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Plot sum of shap value per feature (mean feature value color coded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values[0].sum(axis=(1))[:, ten_most_important_features_by_mean_abs_shap], pd.DataFrame(data=test_X_np.mean(axis=(1)), columns = features)[np.array(features)[ten_most_important_features_by_mean_abs_shap]],max_display=13, show=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Reduce time dimension\n",
    "\n",
    "Time dimension can be reduced with reshape, mean and sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten subjects and time dimension\n",
    "\n",
    "shap_values_2D = shap_values[0].reshape(-1,n_channels)\n",
    "X_test_2D = test_X_np.reshape(-1,n_channels)\n",
    "\n",
    "\n",
    "shap_values_2D.shape, X_test_2D.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_2d = pd.DataFrame(data=X_test_2D, columns = features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_2d.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "shap.summary_plot(shap_values_2D, x_test_2d,max_display=100, show=True)\n",
    "# plt.savefig(os.path.join('/Users/jk1/Downloads', 'shap_summary_plot.png'), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "feature = 11\n",
    "feature_name = list(test_features_lookup_table['sample_label'].keys())[list(test_features_lookup_table['sample_label'].values()).index(feature)]\n",
    "sns.scatterplot(x=shap_values_2D[:,feature], y=x_test_2d[feature_name], hue=x_test_2d[feature_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n_columns = 4\n",
    "n_rows = n_channels // n_columns + 1\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_columns, figsize=(n_columns*3.5, n_rows*3.5))\n",
    "\n",
    "for f in range(n_channels):\n",
    "    feature_name = list(test_features_lookup_table['sample_label'].keys())[list(test_features_lookup_table['sample_label'].values()).index(f)]\n",
    "    ax = axes[f//n_columns, f%n_columns]\n",
    "    sns.scatterplot(y=shap_values_2D[:,f], x=x_test_2d[feature_name], hue=x_test_2d[feature_name], ax=ax)\n",
    "    ax.set_title(feature_name)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values_2D, x_test_2d, plot_type=\"bar\", max_display=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Sum over time dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values_2D = shap_values[0].sum(axis=1)\n",
    "X_test_2D = test_X_np.mean(axis=1)\n",
    "x_test_2d = pd.DataFrame(data=X_test_2D, columns = features)\n",
    "\n",
    "\n",
    "shap_values_2D.shape, X_test_2D.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n_columns = 4\n",
    "n_rows = n_channels // n_columns + 1\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_columns, figsize=(n_columns*3.5, n_rows*3.5))\n",
    "\n",
    "for f in range(n_channels):\n",
    "    feature_name = list(test_features_lookup_table['sample_label'].keys())[list(test_features_lookup_table['sample_label'].values()).index(f)]\n",
    "    ax = axes[f//n_columns, f%n_columns]\n",
    "    sns.scatterplot(y=shap_values_2D[:,f], x=x_test_2d[feature_name], hue=x_test_2d[feature_name], ax=ax)\n",
    "    ax.set_title(feature_name)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### SHAP dependence plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.dependence_plot(\"uree\", shap_values_2D, x_test_2d, interaction_index=\"creatinine\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "As expected, strong interaction between uree and creatinine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# automatic choice of interaction\n",
    "shap.dependence_plot(\"age\", shap_values_2D, x_test_2d)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## SHAP at each timestep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "len_test_set = X_test_2D.shape[0]\n",
    "len_test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "## SHAP for each time step\n",
    "\n",
    "for step in range(n_time_steps):\n",
    "    index = [i for i in list(range(len_test_set)) if i%n_time_steps == step]\n",
    "    shap_values_2D_step = shap_values_2D[index]\n",
    "    x_test_2d_step = x_test_2d.iloc[index]\n",
    "    print(\"_______ time step {} ___________\".format(step))\n",
    "    shap.summary_plot(shap_values_2D_step, x_test_2d_step, plot_type=\"bar\")\n",
    "    shap.summary_plot(shap_values_2D_step, x_test_2d_step)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# plot for last time steps\n",
    "step = 71\n",
    "index = [i for i in list(range(len_test_set)) if i%n_time_steps == step]\n",
    "shap_values_2D_step = shap_values_2D[index]\n",
    "x_test_2d_step = x_test_2d.iloc[index]\n",
    "shap.summary_plot(shap_values_2D_step, x_test_2d_step, plot_type=\"bar\", show=True)\n",
    "plt.close()\n",
    "shap.summary_plot(shap_values_2D_step, x_test_2d_step, show=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "feature = \"age\"\n",
    "feature_idx = x_test_2d_step.columns.get_loc(feature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "feature_shap_values_2D_step = shap_values_2D_step[:,feature_idx:feature_idx+1]\n",
    "feature_x_test_2d_step = x_test_2d_step[[feature]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "feature_shap_values_2D_step.shape, feature_x_test_2d_step.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "shap.summary_plot(feature_shap_values_2D_step, feature_x_test_2d_step, show=False, max_display=1)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## GradientExplainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Use the training data for deep explainer => can use fewer instances\n",
    "explainer_2 = shap.GradientExplainer(model, train_X_np)\n",
    "# explain the testing instances (can use fewer instances)\n",
    "# explaining each prediction requires 2 * background dataset size runs\n",
    "shap_values_2 = explainer_2.shap_values(test_X_np)\n",
    "# init the JS visualization code\n",
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "################# Plot AVERAGE shap values for ALL subjects  #####################\n",
    "## Consider ABSOLUTE of SHAP values ##\n",
    "shap_average_abs_value_2 = np.abs(shap_values_2[0]).mean(axis=0)\n",
    "\n",
    "x_average_value = pd.DataFrame(data=test_X_np.mean(axis=0), columns = features)\n",
    "shap.force_plot(0, shap_average_abs_value_2, x_average_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Importance for each training instance with SHAP GradientExplainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "################# Plot AVERAGE shap values for ALL training subjects  #####################\n",
    "## Consider ABSOLUTE of SHAP values ##\n",
    "shap.initjs()\n",
    "shap_values_train = explainer.shap_values(train_X_np)\n",
    "\n",
    "shap_average_abs_value_train = np.abs(shap_values_train[0]).mean(axis=0)\n",
    "\n",
    "x_average_value_train = pd.DataFrame(data=train_X_np.mean(axis=0), columns = features)\n",
    "shap.force_plot(0, shap_average_abs_value_train, x_average_value_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "shap_values_train_2D = shap_values_train[0].reshape(-1,n_channels)\n",
    "X_train_2D = train_X_np.reshape(-1,n_channels)\n",
    "\n",
    "\n",
    "shap.summary_plot(shap_values_train_2D, X_train_2D, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# COLOR: https://seaborn.pydata.org/tutorial/color_palettes.html\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i, feature in enumerate(features):\n",
    "    print(feature)\n",
    "\n",
    "    plt.figure(figsize = (8,6))\n",
    "    tmp = shap_values_train[0][:,:,i].reshape((-1,n_time_steps))\n",
    "    print(tmp.shape)\n",
    "    plot_shap = sns.heatmap(tmp, cmap=\"coolwarm\")\n",
    "    plt.show(plot_shap)\n",
    "    print(\"-----------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

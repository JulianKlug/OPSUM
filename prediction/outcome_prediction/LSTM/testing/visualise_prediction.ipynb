{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Interactive visualisation of the prediction for a single subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randint\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from preprocessing.preprocessing_tools.normalisation.reverse_normalisation import reverse_normalisation\n",
    "from prediction.utils.scoring import precision, recall, matthews\n",
    "from prediction.outcome_prediction.LSTM.LSTM import lstm_generator\n",
    "from prediction.outcome_prediction.LSTM.testing.shap_helper_functions import check_shap_version_compatibility\n",
    "from prediction.outcome_prediction.LSTM.testing.visualisation_helper_functions import reverse_normalisation_for_subj\n",
    "from sklearn.model_selection import train_test_split\n",
    "from prediction.outcome_prediction.data_loading.data_formatting import features_to_numpy, \\\n",
    "    link_patient_id_to_outcome, numpy_to_lookup_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Shap values require very specific versions\n",
    "check_shap_version_compatibility()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Pre-computation\n",
    "\n",
    "*This takes some time to compute and should be run in advance*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_weights_path = '/Users/jk1/temp/opsum_prediction_output/LSTM_72h_testing/3M_mRS02/2022_09_07_1744/test_LSTM_sigmoid_all_unchanged_0.2_2_True_RMSprop_3M mRS 0-2_128_4/sigmoid_all_unchanged_0.2_2_True_RMSprop_3M mRS 0-2_128_4.hdf5'\n",
    "features_path = '/Users/jk1/temp/opsum_prepro_output/old_preprocessing/preprocessed_features_02092022_083046.csv'\n",
    "labels_path = '/Users/jk1/temp/opsum_prepro_output/old_preprocessing/preprocessed_outcomes_02092022_083046.csv'\n",
    "normalisation_parameters_path = '/Users/jk1/temp/opsum_prepro_output/old_preprocessing/logs_02092022_083046/normalisation_parameters.csv'\n",
    "shap_over_time_path = '/Users/jk1/temp/opsum_prediction_output/LSTM_72h_testing/3M_mRS02/2022_09_07_1744/deep_explainer_shap_values_over_ts.pkl'\n",
    "predictions_over_time_path = '/Users/jk1/Downloads/predictions_over_timesteps.pkl'\n",
    "out_dir = '/Users/jk1/Downloads'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome = '3M mRS 0-2'\n",
    "masking = True\n",
    "units = 128\n",
    "activation = 'sigmoid'\n",
    "dropout = 0.2\n",
    "layers = 2\n",
    "optimizer = 'RMSprop'\n",
    "seed = 42\n",
    "test_size = 0.20\n",
    "override_masking_value = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(shap_over_time_path, 'rb') as handle:\n",
    "    shap_values_over_time = pickle.load(handle)\n",
    "\n",
    "normalisation_parameters_df = pd.read_csv(normalisation_parameters_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(predictions_over_time_path, 'rb') as handle:\n",
    "    predictions_over_time = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prediction.outcome_prediction.data_loading.data_formatting import format_to_2d_table_with_time\n",
    "\n",
    "# load the dataset\n",
    "X, y = format_to_2d_table_with_time(feature_df_path=features_path, outcome_df_path=labels_path,\n",
    "                                    outcome=outcome)\n",
    "\n",
    "n_time_steps = X.relative_sample_date_hourly_cat.max() + 1\n",
    "n_channels = X.sample_label.unique().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce every patient to a single outcome (to avoid duplicates)\n",
    "all_pids_with_outcome = link_patient_id_to_outcome(y, outcome)\n",
    "pid_train, pid_test, y_pid_train, y_pid_test = train_test_split(all_pids_with_outcome.patient_id.tolist(),\n",
    "                                                                all_pids_with_outcome.outcome.tolist(),\n",
    "                                                                stratify=all_pids_with_outcome.outcome.tolist(),\n",
    "                                                                test_size=test_size,\n",
    "                                                                random_state=seed)\n",
    "\n",
    "test_X_df = X[X.patient_id.isin(pid_test)]\n",
    "test_y_df = y[y.patient_id.isin(pid_test)]\n",
    "train_X_df = X[X.patient_id.isin(pid_train)]\n",
    "train_y_df = y[y.patient_id.isin(pid_train)]\n",
    "\n",
    "train_X_np = features_to_numpy(train_X_df,\n",
    "                                 ['case_admission_id', 'relative_sample_date_hourly_cat', 'sample_label', 'value'])\n",
    "test_X_np = features_to_numpy(test_X_df,\n",
    "                              ['case_admission_id', 'relative_sample_date_hourly_cat', 'sample_label', 'value'])\n",
    "train_y_np = np.array([train_y_df[train_y_df.case_admission_id == cid].outcome.values[0] for cid in\n",
    "                         train_X_np[:, 0, 0, 0]]).astype('float32')\n",
    "test_y_np = np.array([test_y_df[test_y_df.case_admission_id == cid].outcome.values[0] for cid in\n",
    "                      test_X_np[:, 0, 0, 0]]).astype('float32')\n",
    "\n",
    "\n",
    "# create look-up table for case_admission_ids, sample_labels and relative_sample_date_hourly_cat\n",
    "test_features_lookup_table = numpy_to_lookup_table(test_X_np)\n",
    "train_features_lookup_table = numpy_to_lookup_table(train_X_np)\n",
    "\n",
    "# Remove the case_admission_id, sample_label, and time_step_label columns from the data\n",
    "test_X_np = test_X_np[:, :, :, -1].astype('float32')\n",
    "train_X_np = train_X_np[:, :, :, -1].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(test_features_lookup_table['sample_label'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_normalised_train_X_df = reverse_normalisation(train_X_df, normalisation_parameters_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Choose subject and load or compute prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj = randint(0, len(test_X_np))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(subj, predictions_over_time[-1,subj])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_pred_over_ts = predictions_over_time[:,subj]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subj_pred_over_ts = []\n",
    "# for ts in tqdm(range(n_time_steps)):\n",
    "#     modified_time_steps = ts + 1\n",
    "#     model = lstm_generator(x_time_shape=modified_time_steps, x_channels_shape=n_channels, masking=masking, n_units=units,\n",
    "#                            activation=activation, dropout=dropout, n_layers=layers)\n",
    "#\n",
    "#     model.compile(loss='binary_crossentropy', optimizer=optimizer,\n",
    "#                   metrics=['accuracy', precision, recall, matthews])\n",
    "#\n",
    "#     model.load_weights(model_weights_path)\n",
    "#\n",
    "#     if pre_compute_all_subjects:\n",
    "#         subj_X_with_first_n_ts = test_X_np[:,0:modified_time_steps,:]\n",
    "#     else:\n",
    "#         subj_X_with_first_n_ts = test_X_np[subj:subj+1,0:modified_time_steps,:]\n",
    "#\n",
    "#     y_pred = model.predict(subj_X_with_first_n_ts)\n",
    "#     subj_pred_over_ts.append(y_pred[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Plot overall subject prediction & explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a bar plot showing impact of most important features on the prediction across all n_time_steps\n",
    "# find index of 3 features with biggest positive shap impart\n",
    "selected_positive_features = np.squeeze(shap_values_over_time[-1])[subj].sum(axis=0).argsort()[-n_features:][::-1]\n",
    "\n",
    "# find index of 3 features with biggest negative shap impart\n",
    "selected_negative_features = np.squeeze(shap_values_over_time[-1])[subj].sum(axis=0).argsort()[:n_features][::-1]\n",
    "\n",
    "selected_features = np.concatenate((selected_positive_features, selected_negative_features))\n",
    "\n",
    "fig1 = plt.figure(figsize=(15,5))\n",
    "ax1 = fig1.add_subplot(121)\n",
    "ax = sns.barplot(y=np.array(features)[selected_features], x=np.squeeze(shap_values_over_time[-1])[subj].sum(axis=0)[selected_features], palette=\"RdBu_r\")\n",
    "ax.title.set_text(f'SHAP values for subj {subj} ')\n",
    "\n",
    "non_norm_subj_df = reverse_normalisation_for_subj(pd.DataFrame(data=test_X_np[subj], columns = features), normalisation_parameters_df)\n",
    "median_norm_feature_df = non_norm_subj_df.median(axis=0)[selected_features]\n",
    "\n",
    "ax2 = fig1.add_subplot(122)\n",
    "font_size=12\n",
    "bbox=[0, 0, 1, 1]\n",
    "ax2.axis('off')\n",
    "cell_text = []\n",
    "for row in range(len(median_norm_feature_df)):\n",
    "    cell_text.append([median_norm_feature_df.iloc[row].astype(str)])\n",
    "mpl_table = ax2.table(cellText = cell_text, rowLabels = median_norm_feature_df.index, bbox=bbox, colLabels=['Normalised value'], cellLoc='center', colLoc='center', loc='center')\n",
    "mpl_table.auto_set_font_size(False)\n",
    "mpl_table.set_fontsize(font_size)\n",
    "fig1.set_tight_layout(True)\n",
    "# set figure title\n",
    "fig1.suptitle(f'Explanation of prediction for subj {subj} with a probability of good outcome of {subj_pred_over_ts[-1]:.2f}', fontsize=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig1.savefig(os.path.join(out_dir, 'final_prediction.png'), dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Plot relevant features in relation to training population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2 = plt.figure(figsize=(15, 12))\n",
    "plt.subplots_adjust(hspace=0.2)\n",
    "plt.suptitle(\"Selected features\", fontsize=18, y=0.99, x=0.52, horizontalalignment='center')\n",
    "\n",
    "# set number of columns (use 3 to demonstrate the change)\n",
    "ncols = 3\n",
    "# calculate number of rows\n",
    "nrows = len(selected_features) // ncols + (len(selected_features) % ncols > 0)\n",
    "\n",
    "# loop through the length of features and keep track of index\n",
    "for n, feature in enumerate(selected_features):\n",
    "    # add a new subplot iteratively using nrows and cols\n",
    "    ax = plt.subplot(nrows, ncols, n + 1)\n",
    "\n",
    "    temp_pop_df = non_normalised_train_X_df[non_normalised_train_X_df.sample_label == features[feature]]\n",
    "    sns.histplot(temp_pop_df.value, ax=ax)\n",
    "    plt.scatter(median_norm_feature_df[features[feature]], 0, marker='o', s=500)\n",
    "    if (n % ncols) == 1:\n",
    "        if n <= len(selected_features) / 2:\n",
    "            ax.set_title(r\"$\\bf{Positive\\ features}$\" +f'\\n\\n{features[feature]}')\n",
    "        else:\n",
    "            ax.set_title(r\"$\\bf{Negative\\ features}$\" + f'\\n\\n{features[feature]}')\n",
    "\n",
    "    else:\n",
    "        ax.set_title(features[feature])\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig2.savefig(os.path.join(out_dir, 'features_histogram_comparison.png'), dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Plot evolution of prediction & explanation over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_prevailing_features = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_shap_values_over_time = np.array([shap_values_over_time[ts][0].sum(axis=1) for ts in range(n_time_steps)])\n",
    "\n",
    "# find index of 3 features with biggest positive shap impart & index of 3 features with biggest negative shap impart\n",
    "if overall_prevailing_features:\n",
    "    # prevailing features over cumulative time\n",
    "    selected_negative_features = cumulative_shap_values_over_time[:, subj].sum(axis=0).argsort()[:n_features][::-1]\n",
    "    selected_positive_features = cumulative_shap_values_over_time[:, subj].sum(axis=0).argsort()[-n_features:][::-1]\n",
    "else:\n",
    "    # prevailing features at last timepoint\n",
    "    selected_positive_features = np.squeeze(shap_values_over_time[-1])[subj].sum(axis=0).argsort()[-n_features:][::-1]\n",
    "    selected_negative_features = np.squeeze(shap_values_over_time[-1])[subj].sum(axis=0).argsort()[:n_features][::-1]\n",
    "\n",
    "selected_features = np.concatenate((selected_positive_features, selected_negative_features))\n",
    "\n",
    "fig3 = plt.figure(figsize=(15,10))\n",
    "\n",
    "k=1\n",
    "alpha=0.3\n",
    "\n",
    "timestep_axis = np.array(range(n_time_steps))\n",
    "\n",
    "positive_color_palette = sns.color_palette(\"mako\", n_colors=len(selected_positive_features))\n",
    "negative_color_palette = sns.color_palette(\"flare_r\", n_colors=len(selected_negative_features))\n",
    "\n",
    "timestep_axis = np.array(range(n_time_steps))\n",
    "ax = sns.lineplot(x=timestep_axis, y=subj_pred_over_ts, label='probability', linewidth = 2)\n",
    "\n",
    "\n",
    "pos_baseline = subj_pred_over_ts\n",
    "neg_baseline = subj_pred_over_ts\n",
    "pos_count = 0\n",
    "neg_count = 0\n",
    "for i, feature in enumerate(selected_features):\n",
    "    subj_cumulative_shap_value_over_time = cumulative_shap_values_over_time[:, subj, feature]\n",
    "    positive_portion = (subj_cumulative_shap_value_over_time > 0)\n",
    "    negative_portion = (subj_cumulative_shap_value_over_time < 0)\n",
    "\n",
    "    pos_function = subj_cumulative_shap_value_over_time.copy()\n",
    "    pos_function[negative_portion] = 0\n",
    "\n",
    "    neg_function = subj_cumulative_shap_value_over_time.copy()\n",
    "    neg_function[positive_portion] = 0\n",
    "\n",
    "    if feature in selected_positive_features:\n",
    "        feature_color = positive_color_palette[pos_count]\n",
    "        pos_count += 1\n",
    "    else:\n",
    "        feature_color = negative_color_palette[neg_count]\n",
    "        neg_count += 1\n",
    "\n",
    "    positive_feature = pos_baseline + k * pos_function\n",
    "    ax.fill_between(timestep_axis, pos_baseline, positive_feature, color=feature_color, alpha=alpha, label=features[feature])\n",
    "    pos_baseline = positive_feature\n",
    "\n",
    "    negative_feature = neg_baseline + k * neg_function\n",
    "    ax.fill_between(timestep_axis, negative_feature, neg_baseline, color=feature_color, alpha=alpha)\n",
    "    neg_baseline = negative_feature\n",
    "\n",
    "ax.legend(fontsize='x-large')\n",
    "\n",
    "ax.set_title(f'Predictions for subject {subj} of test set along time', fontsize=20)\n",
    "ax.set_xlabel('Time from admission (hours)', fontsize=15)\n",
    "ax.set_ylabel('Probability of favorable outcome', fontsize=15)\n",
    "\n",
    "plt.plot()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig3.savefig(os.path.join(out_dir, 'prediction_over_time.png'), dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Plot selected features over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig4 = plt.figure(figsize=(15, 12))\n",
    "plt.subplots_adjust(hspace=0.2)\n",
    "plt.suptitle(\"Selected features\", fontsize=18, y=0.99, x=0.52, horizontalalignment='center')\n",
    "\n",
    "# set number of columns (use 3 to demonstrate the change)\n",
    "ncols = 3\n",
    "# calculate number of rows\n",
    "nrows = len(selected_features) // ncols + (len(selected_features) % ncols > 0)\n",
    "\n",
    "pos_count = 0\n",
    "neg_count = 0\n",
    "# loop through the length of features and keep track of index\n",
    "for n, feature in enumerate(selected_features):\n",
    "    # add a new subplot iteratively using nrows and cols\n",
    "    ax = plt.subplot(nrows, ncols, n + 1)\n",
    "\n",
    "    if feature in selected_positive_features:\n",
    "        feature_color = positive_color_palette[pos_count]\n",
    "        pos_count += 1\n",
    "    else:\n",
    "        feature_color = negative_color_palette[neg_count]\n",
    "        neg_count += 1\n",
    "    sns.lineplot(y=features[feature], x='index', data=non_norm_subj_df.reset_index(), color=feature_color, ax=ax)\n",
    "\n",
    "    if (n % ncols) == 1:\n",
    "        if n <= len(selected_features) / 2:\n",
    "            ax.set_title(r\"$\\bf{Positive\\ features}$\" +f'\\n\\n{features[feature]}')\n",
    "        else:\n",
    "            ax.set_title(r\"$\\bf{Negative\\ features}$\" + f'\\n\\n{features[feature]}')\n",
    "    else:\n",
    "        ax.set_title(features[feature])\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig4.savefig(os.path.join(out_dir, 'features_over_time.png'), dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Plot contribution of a specific feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = [\"median_mean_blood_pressure\", \"median_diastolic_blood_pressure\", \"median_systolic_blood_pressure\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features_idx = [np.where(np.array(features) == selected_feature)[0][0] for selected_feature in selected_features]\n",
    "selected_features_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_shap_values_over_time = np.array([shap_values_over_time[ts][0].sum(axis=1) for ts in range(n_time_steps)])\n",
    "subj_pred_over_ts = predictions_over_time[:,subj]\n",
    "\n",
    "fig3 = plt.figure(figsize=(15,10))\n",
    "\n",
    "k=1\n",
    "alpha=0.3\n",
    "\n",
    "timestep_axis = np.array(range(n_time_steps))\n",
    "\n",
    "positive_color_palette = sns.color_palette(\"mako\", n_colors=len(selected_positive_features))\n",
    "negative_color_palette = sns.color_palette(\"flare_r\", n_colors=len(selected_negative_features))\n",
    "\n",
    "timestep_axis = np.array(range(n_time_steps))\n",
    "ax = sns.lineplot(x=timestep_axis, y=subj_pred_over_ts, label='probability', linewidth = 2)\n",
    "ax2 = ax.twinx()\n",
    "\n",
    "\n",
    "pos_baseline = subj_pred_over_ts\n",
    "neg_baseline = subj_pred_over_ts\n",
    "pos_count, neg_count = 0, 0\n",
    "for i, feature in enumerate(selected_features_idx):\n",
    "    subj_cumulative_shap_value_over_time = cumulative_shap_values_over_time[:, subj, feature]\n",
    "    positive_portion = (subj_cumulative_shap_value_over_time > 0)\n",
    "    negative_portion = (subj_cumulative_shap_value_over_time < 0)\n",
    "\n",
    "    pos_function = subj_cumulative_shap_value_over_time.copy()\n",
    "    pos_function[negative_portion] = 0\n",
    "\n",
    "    neg_function = subj_cumulative_shap_value_over_time.copy()\n",
    "    neg_function[positive_portion] = 0\n",
    "\n",
    "    if sum(subj_cumulative_shap_value_over_time) > 0:\n",
    "        feature_color = positive_color_palette[pos_count]\n",
    "        pos_count += 1\n",
    "    else:\n",
    "        feature_color = negative_color_palette[neg_count]\n",
    "        neg_count += 1\n",
    "\n",
    "    positive_feature = pos_baseline + k * pos_function\n",
    "    ax.fill_between(timestep_axis, pos_baseline, positive_feature, color=feature_color, alpha=alpha, label=features[feature])\n",
    "    pos_baseline = positive_feature\n",
    "\n",
    "    negative_feature = neg_baseline + k * neg_function\n",
    "    ax.fill_between(timestep_axis, negative_feature, neg_baseline, color=feature_color, alpha=alpha)\n",
    "    neg_baseline = negative_feature\n",
    "\n",
    "    sns.scatterplot(y=features[feature], x='index', data=non_norm_subj_df.reset_index(), ax=ax2, legend=False, color=feature_color)\n",
    "\n",
    "ax.legend(fontsize='x-large')\n",
    "\n",
    "ax.set_title(f'Predictions for subject {subj} of test set along time', fontsize=20)\n",
    "ax.set_xlabel('Time from admission (hours)', fontsize=15)\n",
    "ax.set_ylabel('Probability of favorable outcome', fontsize=15)\n",
    "\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig4 = plt.figure(figsize=(15, 12))\n",
    "plt.subplots_adjust(hspace=0.2)\n",
    "plt.suptitle(\"Selected features\", fontsize=18, y=0.99, x=0.52, horizontalalignment='center')\n",
    "\n",
    "# set number of columns (use 3 to demonstrate the change)\n",
    "ncols = 3\n",
    "# calculate number of rows\n",
    "nrows = len(selected_features_idx) // ncols + (len(selected_features_idx) % ncols > 0)\n",
    "\n",
    "pos_count = 0\n",
    "neg_count = 0\n",
    "# loop through the length of features and keep track of index\n",
    "for n, feature in enumerate(selected_features_idx):\n",
    "    # add a new subplot iteratively using nrows and cols\n",
    "    ax = plt.subplot(nrows, ncols, n + 1)\n",
    "\n",
    "    if sum(subj_cumulative_shap_value_over_time) > 0:\n",
    "        feature_color = positive_color_palette[pos_count]\n",
    "        pos_count += 1\n",
    "    else:\n",
    "        feature_color = negative_color_palette[neg_count]\n",
    "        neg_count += 1\n",
    "    sns.lineplot(y=features[feature], x='index', data=non_norm_subj_df.reset_index(), color=feature_color, ax=ax)\n",
    "\n",
    "    ax.set_title(features[feature])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values_over_time[-1][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "auto=False\n",
    "\n",
    "X_test_2D = test_X_np.reshape(-1,n_channels)\n",
    "shap_values_2D = shap_values_over_time[-1][0].reshape(-1,n_channels)\n",
    "x_test_2d = pd.DataFrame(data=X_test_2D, columns = features)\n",
    "\n",
    "for n, feature in enumerate(selected_features_idx):\n",
    "    if auto == True:\n",
    "        # automatic choice of interaction\n",
    "        shap.dependence_plot(features[feature], shap_values_2D, x_test_2d)\n",
    "    else:\n",
    "        shap.dependence_plot(features[feature], shap_values_2D, x_test_2d, interaction_index=\"median_NIHSS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

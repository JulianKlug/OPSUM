{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2083d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../../Transformer/architecture.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4484c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "# %%\n",
    "\n",
    "# %%\n",
    "\n",
    "\n",
    "import optuna\n",
    "from functools import partial\n",
    "import torch as ch\n",
    "import json\n",
    "import torch as ch\n",
    "import matplotlib.pyplot as plt\n",
    "import os, traceback\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import roc_auc_score, matthews_corrcoef\n",
    "import argparse\n",
    "import sys\n",
    "import os\n",
    "from functools import partial\n",
    "from torch import optim, nn, utils, Tensor\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import optuna\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "import pytorch_lightning as pl\n",
    "import os\n",
    "from functools import partial\n",
    "from torch import optim, nn, utils, Tensor\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "import pytorch_lightning as pl\n",
    "from torchmetrics import AUROC\n",
    "from torchmetrics.classification import Accuracy\n",
    "from pytorch_lightning.callbacks.callback import Callback\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sys.path.insert(0, '/home/guillaume/julian/OPSUM/')\n",
    "\n",
    "\n",
    "from prediction.outcome_prediction.LSTM.training.utils import initiate_log_files\n",
    "from prediction.outcome_prediction.data_loading.data_formatting import format_to_2d_table_with_time,     link_patient_id_to_outcome, features_to_numpy, numpy_to_lookup_table, feature_order_verification\n",
    "from prediction.utils.scoring import precision, matthews, recall\n",
    "from prediction.utils.utils import generate_balanced_arrays, check_data, ensure_dir, save_json\n",
    "from prediction.outcome_prediction.LSTM.LSTM import lstm_generator\n",
    "\n",
    "\n",
    "try:\n",
    "    from pytorch_lightning.loggers import LightningLoggerBase\n",
    "except: \n",
    "    from pytorch_lightning.loggers.logger import Logger as LightningLoggerBase\n",
    "\n",
    "class DictLogger(LightningLoggerBase):\n",
    "    \"\"\"PyTorch Lightning `dict` logger.\"\"\"\n",
    "\n",
    "    def __init__(self, version):\n",
    "        super(DictLogger, self).__init__()\n",
    "        self.metrics = []\n",
    "        self._version = version\n",
    "\n",
    "    def log_metrics(self, metrics, step=None):\n",
    "        self.metrics.append(metrics)\n",
    "\n",
    "    @property\n",
    "    def version(self):\n",
    "        return self._version\n",
    "\n",
    "    @property\n",
    "    def experiment(self):\n",
    "        \"\"\"Return the experiment object associated with this logger.\"\"\"\n",
    "\n",
    "    def log_hyperparams(self, params):\n",
    "        \"\"\"\n",
    "        Record hyperparameters.\n",
    "        Args:\n",
    "            params: :class:`~argparse.Namespace` containing the hyperparameters\n",
    "        \"\"\"\n",
    "\n",
    "    @property\n",
    "    def name(self):\n",
    "        \"\"\"Return the experiment name.\"\"\"\n",
    "        return 'optuna'\n",
    "\n",
    "    \n",
    "class MyEarlyStopping(Callback):\n",
    "    \n",
    "    best_so_far = 0\n",
    "    last_improvement = 0\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def on_validation_end(self, trainer, pl_module):\n",
    "        logs = trainer.callback_metrics\n",
    "        val_auroc = logs['val_auroc'].item()\n",
    "        \n",
    "        if val_auroc > self.best_so_far:\n",
    "            self.last_improvement = 0\n",
    "        else:\n",
    "            self.last_improvement += 1\n",
    "            \n",
    "        trainer.should_stop = val_auroc < 0.75 * self.best_so_far or self.last_improvement > 10\n",
    "        \n",
    "        self.best_so_far = max(val_auroc, self.best_so_far)\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "\n",
    "\n",
    "def prepare_dataset(scenario):\n",
    "    X_train, X_val, y_train, y_val = scenario\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train.reshape(-1, 84)).reshape(X_train.shape)\n",
    "    # X_train_neg = X_train[y_train == 0]\n",
    "    # X_train_pos = X_train[np.random.choice(np.where(y_train==1)[0], X_train_neg.shape[0])]\n",
    "    # X_train = np.concatenate([X_train_neg, X_train_pos])\n",
    "    # y_train = np.concatenate([np.zeros(X_train_neg.shape[0]), np.ones(X_train_pos.shape[0])])\n",
    "    X_val = scaler.transform(X_val.reshape(-1, 84)).reshape(X_val.shape)\n",
    "    train_dataset = TensorDataset(ch.from_numpy(X_train).cuda(), ch.from_numpy(y_train.astype(np.int32)).cuda())\n",
    "    val_dataset = TensorDataset(ch.from_numpy(X_val).cuda(), ch.from_numpy(y_val.astype(np.int32)).cuda())\n",
    "    return train_dataset, val_dataset\n",
    "\n",
    "\n",
    "# %%\n",
    "\n",
    "\n",
    "scenarios = ch.load('/home/guillaume/julian/data_splits_death.pth')\n",
    "all_datasets = [prepare_dataset(x) for x in scenarios]\n",
    "\n",
    "\n",
    "# %%\n",
    "\n",
    "\n",
    "# define the LightningModule\n",
    "class LitModel(pl.LightningModule):\n",
    "    def __init__(self, model, lr, wd, train_noise):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.lr = lr\n",
    "        self.wd = wd\n",
    "        self.train_noise = train_noise\n",
    "        self.criterion = ch.nn.BCEWithLogitsLoss()\n",
    "        self.train_accuracy = Accuracy(task='binary')\n",
    "        self.train_accuracy_epoch = Accuracy(task='binary')\n",
    "        self.val_accuracy_epoch = Accuracy(task='binary')\n",
    "        self.train_auroc = AUROC(task=\"binary\")\n",
    "        self.val_auroc = AUROC(task=\"binary\")\n",
    "\n",
    "    def training_step(self, batch, batch_idx, mode='train'):\n",
    "        x, y = batch\n",
    "        if self.train_noise != 0:\n",
    "            x = x + ch.randn_like(x) * self.train_noise\n",
    "        predictions = self.model(x).squeeze().ravel()\n",
    "        y = y.unsqueeze(1).repeat(1, x.shape[1]).ravel()\n",
    "        loss = self.criterion(predictions, y.float()).ravel()\n",
    "        self.train_accuracy(predictions.ravel(), y.ravel())\n",
    "        self.train_accuracy_epoch(predictions.ravel(), y.ravel())\n",
    "        # self.train_auroc(ch.sigmoid(predictions.ravel()), y.ravel())\n",
    "        # self.log(\"train_auroc\", self.train_auroc, on_step=True, on_epoch=False, prog_bar=True)\n",
    "        self.log(\"train_loss\", loss, on_step=True, on_epoch=False, prog_bar=True)\n",
    "        self.log(\"train_loss_epoch\", loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"train_acc_epoch\", self.train_accuracy_epoch, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self,batch, batch_idx, mode='train'):\n",
    "        x, y = batch\n",
    "        predictions = self.model(x).squeeze().ravel()\n",
    "        y = y.unsqueeze(1).repeat(1, x.shape[1]).ravel()\n",
    "        loss = self.criterion(predictions, y.float()).ravel()\n",
    "        self.val_auroc(ch.sigmoid(predictions.ravel()), y.ravel())\n",
    "        self.val_accuracy_epoch(predictions.ravel(), y.ravel())\n",
    "        self.log(\"val_auroc\", self.val_auroc, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"val_loss\", loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"val_accuracy\", self.val_accuracy_epoch, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=self.lr, weight_decay=self.wd)\n",
    "        # optimizer = optim.SGD(self.parameters(), lr=self.lr, weight_decay=self.wd)\n",
    "        \n",
    "        return [optimizer], [optim.lr_scheduler.ExponentialLR(optimizer, 0.99)]\n",
    "\n",
    "\n",
    "# %%\n",
    "\n",
    "\n",
    "from uuid import uuid4\n",
    "import json\n",
    "\n",
    "def get_score(all_ds):\n",
    "    # bs = trial.suggest_categorical(\"batch_size\", choices=[32, 64])\n",
    "    # num_layers = trial.suggest_categorical(\"num_layers\", choices=[1, 2, 4, 8, 12, 16])\n",
    "    # model_dim = trial.suggest_categorical(\"model_dim\", choices=[128, 256, 512])\n",
    "    # train_noise = trial.suggest_loguniform(\"train_noise\", 1e-5, 7)\n",
    "    # wd = trial.suggest_loguniform(\"weight_decay\", 1e-5, 10)\n",
    "    # ff_factor = 2\n",
    "    # ff_dim = ff_factor * model_dim\n",
    "    # dropout = trial.suggest_uniform(\"dropout\", 0, 1)\n",
    "    # num_heads = trial.suggest_categorical(\"num_head\", [8])\n",
    "    # pos_encode_factor = trial.suggest_loguniform(\"pos_encode_factor\", 1e-5, 10)\n",
    "    \n",
    "    bs = 64\n",
    "    num_layers = 8\n",
    "    model_dim = 16\n",
    "    wd = 5e-6\n",
    "    train_noise = 0.8\n",
    "    lr = 2e-4\n",
    "    ff_factor = 2\n",
    "    ff_dim = ff_factor * model_dim\n",
    "    dropout = 0\n",
    "    pos_encode_factor = 3\n",
    "    num_heads = 8\n",
    "    scores = [] \n",
    "    ts = []\n",
    "    \n",
    "    loggers = []\n",
    "    \n",
    "    for i, (train_dataset, val_dataset) in enumerate(all_ds):\n",
    "        model = OPSUMTransformer(\n",
    "            input_dim=84,\n",
    "            num_layers=num_layers,\n",
    "            model_dim=model_dim,\n",
    "            dropout=dropout,\n",
    "            ff_dim=ff_dim,\n",
    "            num_heads=num_heads,\n",
    "            num_classes=1,\n",
    "            max_dim=500,\n",
    "            pos_encode_factor=pos_encode_factor\n",
    "        )\n",
    "\n",
    "        train_loader = DataLoader(train_dataset, batch_size=bs, shuffle=True, drop_last=True )\n",
    "        val_loader = DataLoader(val_dataset, batch_size=1024)\n",
    "        logger = DictLogger(0)\n",
    "        module = LitModel(model, lr, wd, train_noise)\n",
    "        trainer = pl.Trainer(accelerator='gpu', devices=1, max_epochs=100,logger=logger,\n",
    "                             callbacks=[MyEarlyStopping()], gradient_clip_val=1)\n",
    "        trainer.fit(model=module, train_dataloaders=train_loader, val_dataloaders=val_loader)\n",
    "        val_aurocs = np.array([x['val_auroc'] for x in logger.metrics if 'val_auroc' in x])\n",
    "        best_idx = np.argmax(val_aurocs)\n",
    "        actual_score = np.median(val_aurocs[max(0, best_idx -1): best_idx + 2])\n",
    "        return actual_score\n",
    "        \n",
    "    return loggers\n",
    "\n",
    "# %%\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb5eeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = get_score(all_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f22ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733c1f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([v for x in log.metrics for (k, v) in x.items() if v != 0 if k=='val_auroc'], label='new')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb19999",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([v for x in log.metrics for (k, v) in x.items() if v != 0 if k=='train_loss_epoch'], label='new')\n",
    "plt.plot(old, label='old')\n",
    "plt.legend()\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330e5e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "old = [v for x in log.metrics for (k, v) in x.items() if v != 0 if k=='train_loss_epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c057b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([v for x in log.metrics for (k, v) in x.items() if v != 0 if k=='train_acc_epoch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c85512e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caed6c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([v for x in log.metrics for (k, v) in x.items() if v != 0 if k=='train_loss_epoch'])\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4fa13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "log.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ad9665",
   "metadata": {},
   "outputs": [],
   "source": [
    "(r > 0).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68454259",
   "metadata": {},
   "outputs": [],
   "source": [
    "features.std(1).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59cf02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c189c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_d = [v for x in log.metrics for (k, v) in x.items() if v != 0 if k=='val_accuracy']\n",
    "plt.plot(new_d, label='new')\n",
    "# plt.plot(prev, label='old')\n",
    "plt.ylim(0.86, 0.91)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee6c073",
   "metadata": {},
   "outputs": [],
   "source": [
    "prev = new_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048f8baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(prev)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

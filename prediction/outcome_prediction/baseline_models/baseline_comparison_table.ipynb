{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-03T17:50:43.068218Z",
     "start_time": "2023-05-03T17:50:43.061954Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-03T17:50:43.438551Z",
     "start_time": "2023-05-03T17:50:43.432139Z"
    }
   },
   "outputs": [],
   "source": [
    "baseline_performance_path = '/Users/jk1/temp/opsum_prediction_output/baseline_models/mrs02_clinical_scores_results.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-03T17:50:43.701606Z",
     "start_time": "2023-05-03T17:50:43.695027Z"
    }
   },
   "outputs": [],
   "source": [
    "output_dir = '/Users/jk1/Downloads'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-03T17:50:43.957694Z",
     "start_time": "2023-05-03T17:50:43.951166Z"
    }
   },
   "outputs": [],
   "source": [
    "baseline_performance_df = pd.read_csv(baseline_performance_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-03T17:50:44.528981Z",
     "start_time": "2023-05-03T17:50:44.519861Z"
    }
   },
   "outputs": [],
   "source": [
    "baseline_performance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-03T17:50:45.812397Z",
     "start_time": "2023-05-03T17:50:45.809972Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_df(df, model_name, outcome, dataset_name):\n",
    "    preprocessed_df = pd.DataFrame()\n",
    "    # report result rounded to 3 decimal places with 95% CI\n",
    "    preprocessed_df['ROC AUC'] = [f'{round(df[\"auc_test\"].values[0], 3):.3f} ({round(df[\"auc_test_lower_ci\"].values[0], 3):.3f}-{round(df[\"auc_test_upper_ci\"].values[0], 3):.3f})']\n",
    "    preprocessed_df[\"Matthew's Coefficient\"] = [f'{round(df[\"matthews_test\"].values[0], 3):.3f} ({round(df[\"matthews_test_lower_ci\"].values[0], 3):.3f}-{round(df[\"matthews_test_upper_ci\"].values[0], 3):.3f})']\n",
    "    preprocessed_df[\"Accuracy\"] = [f'{round(df[\"accuracy_test\"].values[0], 3):.3f} ({round(df[\"accuracy_test_lower_ci\"].values[0], 3):.3f}-{round(df[\"accuracy_test_upper_ci\"].values[0], 3):.3f})']\n",
    "    preprocessed_df[\"Precision (positive predictive value)\"] = [f'{round(df[\"precision_test\"].values[0], 3):.3f} ({round(df[\"precision_test_lower_ci\"].values[0], 3):.3f}-{round(df[\"precision_test_upper_ci\"].values[0], 3):.3f})']\n",
    "    preprocessed_df[\"Recall (Sensitivity)\"] = [f'{round(df[\"recall_test\"].values[0], 3):.3f} ({round(df[\"recall_test_lower_ci\"].values[0], 3):.3f}-{round(df[\"recall_test_upper_ci\"].values[0], 3):.3f})']\n",
    "    if 'specificity_test' in df.columns:\n",
    "        preprocessed_df[\"Specificity\"] = [f'{round(df[\"specificity_test\"].values[0], 3):.3f} ({round(df[\"specificity_test_lower_ci\"].values[0], 3):.3f}-{round(df[\"specificity_test_upper_ci\"].values[0], 3):.3f})']\n",
    "    else:\n",
    "        preprocessed_df[\"Specificity\"] = [f'NA']\n",
    "\n",
    "    preprocessed_df['Model'] = [model_name]\n",
    "    preprocessed_df['Outcome'] = [outcome]\n",
    "    preprocessed_df['Dataset'] = [dataset_name]\n",
    "\n",
    "    return preprocessed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-03T17:50:47.040549Z",
     "start_time": "2023-05-03T17:50:47.024611Z"
    }
   },
   "outputs": [],
   "source": [
    "processed_thrive_df = preprocess_df(baseline_performance_df[baseline_performance_df.method_name == 'THRIVE'], 'THRIVE', '3M mrs02', 'GSU')\n",
    "processed_thrivec_df = preprocess_df(baseline_performance_df[baseline_performance_df.method_name == 'THRIVEC'], 'THRIVE-C', '3M mrs02', 'GSU')\n",
    "processed_HIAT_df = preprocess_df(baseline_performance_df[baseline_performance_df.method_name == 'HIAT'], 'HIAT', '3M mrs02', 'GSU')\n",
    "processed_span100_df = preprocess_df(baseline_performance_df[baseline_performance_df.method_name == 'span100'], 'SPAN-100', '3M mrs02', 'GSU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-03T17:50:48.643285Z",
     "start_time": "2023-05-03T17:50:48.639817Z"
    }
   },
   "outputs": [],
   "source": [
    "overall_mrs02_results_df = pd.concat([processed_thrive_df, processed_thrivec_df, processed_HIAT_df, processed_span100_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-03T17:50:49.211619Z",
     "start_time": "2023-05-03T17:50:49.205875Z"
    }
   },
   "outputs": [],
   "source": [
    "overall_mrs02_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-03T17:50:59.182335Z",
     "start_time": "2023-05-03T17:50:59.174574Z"
    }
   },
   "outputs": [],
   "source": [
    "# save results as csv\n",
    "overall_mrs02_results_df.to_csv(os.path.join(output_dir, 'mrs02_model_comparison.csv'), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

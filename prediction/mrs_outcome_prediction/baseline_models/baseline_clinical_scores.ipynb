{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from baseline_scores import hiat_score, thrive_score, span100_score\n",
    "from sklearn import metrics\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "stroke_registry_path = '/Users/jk1/OneDrive - unige.ch/stroke_research/geneva_stroke_unit_dataset/data/stroke_registry/post_hoc_modified/stroke_registry_post_hoc_modified.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_df = pd.read_excel(stroke_registry_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# only keep data with '3M mRs' not nan\n",
    "data_df = data_df[data_df['3M mRS'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_df['3M mRS 0-1'] = np.where(data_df['3M mRS'].isna(), np.nan, np.where(data_df['3M mRS'] <= 1, 1, 0))\n",
    "data_df['3M mRS 0-2'] = np.where(data_df['3M mRS'].isna(), np.nan, np.where(data_df['3M mRS'] <= 2, 1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# mrs forwarding (model simply outputs premorbid mrs)\n",
    "data_df['mrs01_forwarding good outcome pred'] = data_df['Prestroke disability (Rankin)'] <= 1\n",
    "data_df['mrs01_forwarding_prob'] = data_df['Prestroke disability (Rankin)'] <= 1\n",
    "data_df['mrs02_forwarding good outcome pred'] = data_df['Prestroke disability (Rankin)'] <= 2\n",
    "data_df['mrs02_forwarding_prob'] = data_df['Prestroke disability (Rankin)'] <= 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_df['HIAT_prob'] =  data_df.apply(\n",
    "    lambda subject: hiat_score(\n",
    "        subject['Age (calc.)'],\n",
    "        subject['NIH on admission'],\n",
    "        subject['1st glucose']),\n",
    "    axis=1)\n",
    "\n",
    "# defined as mRS < 4 at discharge\n",
    "data_df['HIAT good outcome pred'] = data_df['HIAT_prob'] > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_df['span100_prob'] =  data_df.apply(\n",
    "    lambda subject: span100_score(\n",
    "        subject['Age (calc.)'],\n",
    "        subject['NIH on admission']),\n",
    "    axis=1)\n",
    "data_df['span100 good outcome pred'] = data_df['span100_prob'] > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_df['THRIVE_prob'] = data_df.apply(\n",
    "    lambda subject: thrive_score(\n",
    "        subject['Age (calc.)'],\n",
    "        subject['NIH on admission'],\n",
    "        subject['MedHist Hypertension'],\n",
    "        subject['MedHist Diabetes'],\n",
    "        subject['MedHist Atrial Fibr.']\n",
    "    ),\n",
    "    axis=1)\n",
    "\n",
    "data_df['THRIVE good outcome pred'] = data_df['THRIVE_prob'] > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from prediction.mrs_outcome_prediction.baseline_models.baseline_scores import thriveC_score\n",
    "\n",
    "data_df['THRIVEC_prob'] = data_df.apply(\n",
    "    lambda subject: thriveC_score(\n",
    "        subject['Age (calc.)'],\n",
    "        subject['NIH on admission'],\n",
    "        subject['MedHist Hypertension'],\n",
    "        subject['MedHist Diabetes'],\n",
    "        subject['MedHist Atrial Fibr.']\n",
    "    ),\n",
    "    axis=1)\n",
    "\n",
    "data_df['THRIVEC good outcome pred'] = data_df['THRIVEC_prob'] > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_df[['Age (calc.)',\n",
    "        'NIH on admission',\n",
    "        'MedHist Hypertension',\n",
    "        'MedHist Diabetes',\n",
    "        'MedHist Atrial Fibr.', 'THRIVE_prob', 'THRIVE good outcome pred', 'THRIVEC_prob', 'THRIVEC good outcome pred']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "precision = tf.keras.metrics.Precision()\n",
    "recall = tf.keras.metrics.Recall()\n",
    "auc = tf.keras.metrics.AUC()\n",
    "accuracy = tf.keras.metrics.Accuracy()\n",
    "\n",
    "def plot_roc_curve(fpr, tpr, name:str):\n",
    "    sns.lineplot(x=fpr, y=tpr, color='orange', label=name)\n",
    "    sns.lineplot(x=[0, 1], y=[0, 1], color='darkblue', linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'Receiver Operating Characteristic (ROC) Curve of {name}')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "result_columns = ['ground truth', 'method', 'auc', 'accuracy', 'f1', 'precision', 'recall',\n",
    "                  'fpr', 'tpr', 'roc_thresholds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_method(method_name:str, data_df, ground_truth:str='3M mRS 0-1'):\n",
    "    temp_df = data_df[~data_df[f'{method_name}_prob'].isnull()].copy()\n",
    "    method_auc = auc(temp_df[f'{method_name}_prob'], temp_df[ground_truth]).numpy()\n",
    "    method_acc = accuracy(temp_df[f'{method_name} good outcome pred'], temp_df[ground_truth]).numpy()\n",
    "    method_f1 = metrics.f1_score(temp_df[f'{method_name} good outcome pred'],temp_df[ground_truth])\n",
    "    method_precision = precision(temp_df[f'{method_name} good outcome pred'], temp_df[ground_truth]).numpy()\n",
    "    method_recall = recall(temp_df[f'{method_name} good outcome pred'], temp_df[ground_truth]).numpy()\n",
    "    method_fpr, method_tpr, method_thresholds = metrics.roc_curve(\n",
    "                            temp_df[ground_truth],\n",
    "                            temp_df[f'{method_name}_prob']\n",
    "                                                                  )\n",
    "\n",
    "    method_df = pd.DataFrame(\n",
    "        [[ground_truth, method_name, method_auc, method_acc, method_f1, method_precision, method_recall,\n",
    "         method_fpr, method_tpr, method_thresholds]],\n",
    "        columns=result_columns)\n",
    "\n",
    "    plot_roc_curve(method_fpr, method_tpr, method_name)\n",
    "\n",
    "    return method_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "thrive_df = evaluate_method('THRIVE', data_df, ground_truth='3M mRS 0-2')\n",
    "thriveC_df = evaluate_method('THRIVEC', data_df, ground_truth='3M mRS 0-2')\n",
    "hiat_df = evaluate_method('HIAT', data_df, ground_truth='3M mRS 0-2')\n",
    "span100_df = evaluate_method('span100', data_df, ground_truth='3M mRS 0-2')\n",
    "mrs02_forwarding_df = evaluate_method('mrs02_forwarding', data_df, ground_truth='3M mRS 0-2')\n",
    "\n",
    "mrs02_result_df = pd.concat([thrive_df, thriveC_df, hiat_df, span100_df, mrs02_forwarding_df])\n",
    "mrs02_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "thrive_df = evaluate_method('THRIVE', data_df, ground_truth='3M mRS 0-1')\n",
    "thriveC_df = evaluate_method('THRIVEC', data_df, ground_truth='3M mRS 0-1')\n",
    "hiat_df = evaluate_method('HIAT', data_df, ground_truth='3M mRS 0-1')\n",
    "span100_df = evaluate_method('span100', data_df, ground_truth='3M mRS 0-1')\n",
    "mrs01_forwarding_df = evaluate_method('mrs01_forwarding', data_df, ground_truth='3M mRS 0-1')\n",
    "\n",
    "mrs01_result_df = pd.concat([thrive_df, thriveC_df, hiat_df, span100_df, mrs01_forwarding_df])\n",
    "mrs01_result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "output_dir = '/Users/jk1/Downloads'\n",
    "# mrs02_result_df.to_csv(os.path.join(output_dir, 'mrs02_clinical_scores_results.csv'))\n",
    "# mrs01_result_df.to_csv(os.path.join(output_dir, 'mrs01_clinical_scores_results.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
